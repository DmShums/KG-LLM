{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9807256,"sourceType":"datasetVersion","datasetId":6011590},{"sourceId":9821814,"sourceType":"datasetVersion","datasetId":6022519},{"sourceId":5112,"sourceType":"modelInstanceVersion","modelInstanceId":3900,"modelId":1902}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Mistral inference","metadata":{}},{"cell_type":"code","source":"from huggingface_hub.hf_api import HfFolder\n\nHfFolder.save_token('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')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:24:29.650510Z","iopub.execute_input":"2024-11-06T09:24:29.651360Z","iopub.status.idle":"2024-11-06T09:24:30.102302Z","shell.execute_reply.started":"2024-11-06T09:24:29.651320Z","shell.execute_reply":"2024-11-06T09:24:30.101351Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\nimport torch\n\nclass Server:\n\n    def __init__(self): \n\n        # model_id = '/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1'\n        model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n\n        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n\n        self.model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"cuda\")\n\n        self.chat_context = []\n\n        \n\n    def add_system_context(self, message):\n\n        if len(self.chat_context) == 0:\n\n            self.chat_context.insert(0,{\"role\": \"system\", \"content\": message})\n\n        else:\n\n            if self.chat_context[0][\"role\"] == \"system\":\n\n                self.chat_context[0][\"content\"] = message\n\n            else:\n\n                self.chat_context.insert(0,{\"role\": \"system\", \"content\": message})\n\n\n\n    def add_user_context(self, message):\n\n        self.chat_context.append({\"role\": \"user\", \"content\": message})\n\n        \n\n    def add_model_context(self, message):\n\n        self.chat_context.append({\"role\": \"assistant\", \"content\": message})\n\n\n\n    def ask_question(self, message, add_context=False):\n\n        inputs = self.tokenizer.apply_chat_template(\n\n            self.chat_context + [{\"role\": \"user\",\"content\":message}],\n\n            add_generation_prompt=True,\n\n            tokenize=False)\n\n\n\n        inputs = self.tokenizer([inputs], return_tensors = \"pt\")\n\n        inputs.to(self.model.device)\n\n        generated_ids = self.model.generate(inputs.input_ids, max_new_tokens=1000)\n\n\n\n        generated_ids = [\n\n            output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, generated_ids)\n\n        ]\n\n\n\n        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\n\n\n        if add_context:\n\n            self.add_user_context(message)\n\n            self.add_model_context(response.text)\n\n        return response","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:24:30.104262Z","iopub.execute_input":"2024-11-06T09:24:30.104536Z","iopub.status.idle":"2024-11-06T09:24:34.282041Z","shell.execute_reply.started":"2024-11-06T09:24:30.104506Z","shell.execute_reply":"2024-11-06T09:24:34.281054Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"mistral = Server()\n\nmistral.add_system_context(\"Answer as Megatron\")\n\nprint(mistral.ask_question(\"What is Linux?\"))\n\nprint(mistral.ask_question(\"What is asked in previous question?\"))","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:24:34.283882Z","iopub.execute_input":"2024-11-06T09:24:34.284302Z","iopub.status.idle":"2024-11-06T09:31:27.063692Z","shell.execute_reply.started":"2024-11-06T09:24:34.284267Z","shell.execute_reply":"2024-11-06T09:31:27.062748Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16cbe5e83b7e4d8d84c2d9459873326e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51c48424e9b140a4b132381d23949cac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d89642d433446b2b0478f6d3a260883"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb46d05395c84f0999a3534149c79ba9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc8d174749b3476a85d2d9a095124bb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e9203474e2f407aa9a8d996b70063ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bba346f776543a5963eba9b63b7600e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01342ee90495485483c808fb33ad1022"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"556aa9d8af42483eb015cae7db1f048d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6147432646204933b9b0efbddc003e34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acd20c07afda461eb62136fc06ba4ead"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93fcf25432cc4ef894fefbb6f182f4df"}},"metadata":{}},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Greetings, human. Linux is an open-source operating system based on the Unix operating system. It was first created by Linus Torvalds in 1991. Unlike proprietary operating systems, Linux is free to use, modify, and distribute. It's known for its stability, security, and flexibility, making it popular for servers, embedded systems, and personal computers. It's also the foundation for many other operating systems, such as Android and Chrome OS.\nThe previous question asked for a response in the voice of Megatron, a character from the Transformers franchise. However, the question itself did not pose a question or statement for Megatron to respond to. If you have a specific question or statement you'd like Megatron to respond to, please provide it, and I'll do my best to respond in his character's voice. For example, you could ask, \"Megatron, what is your ultimate goal?\" or \"Megatron, how do you feel about the Autobots?\" and I'll provide a response in character.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Ontology access","metadata":{}},{"cell_type":"code","source":"!pip install owlready2\n!pip install rdflib","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:31:27.065044Z","iopub.execute_input":"2024-11-06T09:31:27.065905Z","iopub.status.idle":"2024-11-06T09:32:25.473179Z","shell.execute_reply.started":"2024-11-06T09:31:27.065861Z","shell.execute_reply":"2024-11-06T09:32:25.472053Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting owlready2\n  Downloading owlready2-0.47.tar.gz (27.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: owlready2\n  Building wheel for owlready2 (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for owlready2: filename=owlready2-0.47-cp310-cp310-linux_x86_64.whl size=23515875 sha256=f4f5ab08c4277f5c649c00f446017e14ad7579eb3357311385ef34f84f32d923\n  Stored in directory: /root/.cache/pip/wheels/27/3e/ba/4171c4b10bba9fe1774fbf8fcf794de889e636ce64ad83a533\nSuccessfully built owlready2\nInstalling collected packages: owlready2\nSuccessfully installed owlready2-0.47\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rdflib\n  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting isodate<1.0.0,>=0.7.2 (from rdflib)\n  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyparsing<4,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from rdflib) (3.1.2)\nDownloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\nInstalling collected packages: isodate, rdflib\nSuccessfully installed isodate-0.7.2 rdflib-7.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from owlready2 import *\nimport rdflib\nimport logging\nfrom enum import Enum","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:32:25.475883Z","iopub.execute_input":"2024-11-06T09:32:25.476248Z","iopub.status.idle":"2024-11-06T09:32:25.605811Z","shell.execute_reply.started":"2024-11-06T09:32:25.476213Z","shell.execute_reply":"2024-11-06T09:32:25.605059Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class AnnotationURIs(object):\n    '''\n    This class manages the most common ontology annotations\n    '''\n    def __init__(self):       \n        self.mainLabelURIs = set()\n        self.synonymLabelURIs = set()\n        self.lexicalAnnotationURIs = set()\n                       \n        #Main labels\n        self.mainLabelURIs.add(\"http://www.w3.org/2000/01/rdf-schema#label\")\n        self.mainLabelURIs.add(\"http://www.w3.org/2004/02/skos/core#prefLabel\")\n        self.mainLabelURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000111\")\n        self.mainLabelURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000589\")\n\n        #synonyms or alternative names\n        self.synonymLabelURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasRelatedSynonym\")\n        self.synonymLabelURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasExactSynonym\")\n        self.synonymLabelURIs.add(\"http://www.geneontology.org/formats/oboInOWL#hasExactSynonym\")\n        self.synonymLabelURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasRelatedSynonym\")\n        self.synonymLabelURIs.add(\"http://purl.bioontology.org/ontology/SYN#synonym\")\n        self.synonymLabelURIs.add(\"http://scai.fraunhofer.de/CSEO#Synonym\")\n        self.synonymLabelURIs.add(\"http://purl.obolibrary.org/obo/synonym\")\n        self.synonymLabelURIs.add(\"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#FULL_SYN\")\n        self.synonymLabelURIs.add(\"http://www.ebi.ac.uk/efo/alternative_term\")\n        self.synonymLabelURIs.add(\"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#Synonym\")\n        self.synonymLabelURIs.add(\"http://bioontology.org/projects/ontologies/fma/fmaOwlDlComponent_2_0#Synonym\")\n        self.synonymLabelURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasDefinition\")\n        self.synonymLabelURIs.add(\"http://bioontology.org/projects/ontologies/birnlex#preferred_label\")\n        self.synonymLabelURIs.add(\"http://bioontology.org/projects/ontologies/birnlex#synonyms\")\n        self.synonymLabelURIs.add(\"http://www.w3.org/2004/02/skos/core#altLabel\")\n        self.synonymLabelURIs.add(\"https://cfpub.epa.gov/ecotox#latinName\")\n        self.synonymLabelURIs.add(\"https://cfpub.epa.gov/ecotox#commonName\")\n        self.synonymLabelURIs.add(\"https://www.ncbi.nlm.nih.gov/taxonomy#scientific_name\")\n        self.synonymLabelURIs.add(\"https://www.ncbi.nlm.nih.gov/taxonomy#synonym\")\n        self.synonymLabelURIs.add(\"https://www.ncbi.nlm.nih.gov/taxonomy#equivalent_name\")\n        self.synonymLabelURIs.add(\"https://www.ncbi.nlm.nih.gov/taxonomy#genbank_synonym\")\n        self.synonymLabelURIs.add(\"https://www.ncbi.nlm.nih.gov/taxonomy#common_name\")       \n        #Alternative term       \n        self.synonymLabelURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000118\")\n\n        #Mouse anatomy\n        \n        #Lexically rich interesting\n        self.lexicalAnnotationURIs.update(self.mainLabelURIs)\n        self.lexicalAnnotationURIs.update(self.synonymLabelURIs)\n        \n        self.lexicalAnnotationURIs.add(\"http://www.w3.org/2000/01/rdf-schema#comment\")\n        self.lexicalAnnotationURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasDbXref\")\n\n        self.lexicalAnnotationURIs.add(\"http://purl.org/dc/elements/1.1/description\")\n        self.lexicalAnnotationURIs.add(\"http://purl.org/dc/terms/description\")\n        self.lexicalAnnotationURIs.add(\"http://purl.org/dc/elements/1.1/title\")\n        self.lexicalAnnotationURIs.add(\"http://purl.org/dc/terms/title\")\n        \n        #Definition\n        self.lexicalAnnotationURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000115\")\n        #Elucidation\n        self.lexicalAnnotationURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000600\")\n        #has associated axiomm fol\n        self.lexicalAnnotationURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000602\")\n        #has associated axiomm nl\n        self.lexicalAnnotationURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000601\")\n        self.lexicalAnnotationURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasOBONamespace\")\n    \n    def getAnnotationURIsForSymnonyms(self):\n        return self.synonymLabelURIs\n    \n    def getAnnotationURIsForPreferredLabels(self):\n        return self.mainLabelURIs\n    \n    def getAnnotationURIsForLexicalAnnotations(self):\n        return self.lexicalAnnotationURIs\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:32:25.607168Z","iopub.execute_input":"2024-11-06T09:32:25.607523Z","iopub.status.idle":"2024-11-06T09:32:25.622328Z","shell.execute_reply.started":"2024-11-06T09:32:25.607472Z","shell.execute_reply":"2024-11-06T09:32:25.621174Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Reasoner(Enum):\n    HERMIT=0 #Not really adding the right set of entailments\n    PELLET=1 #Slow for large ontologies\n    STRUCTURAL=2  #Basic domain/range propagation\n    NONE=3 #No reasoning\n\n\nclass OntologyAccess(object):\n    def __init__(self, urionto):\n        logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.DEBUG)\n        self.urionto = urionto\n\n\n    def getOntologyIRI(self):\n        return self.urionto\n\n    def loadOntology(self, reasoner=Reasoner.NONE, memory_java='10240'):\n        #Method from owlready\n        self.onto = get_ontology(self.urionto).load()\n\n        owlready2.reasoning.JAVA_MEMORY=memory_java\n        owlready2.set_log_level(9)\n\n        if reasoner==Reasoner.PELLET:\n\n            try:\n                with self.onto:  #it does add inferences to ontology\n\n                    # Is this wrt data assertions? Check if necessary\n                    # infer_property_values = True, infer_data_property_values = True\n                    logging.info(\"Classifying ontology with Pellet...\")\n                    sync_reasoner_pellet() #it does add inferences to ontology\n\n                    unsat = len(list(self.onto.inconsistent_classes()))\n                    logging.info(\"Ontology successfully classified.\")\n                    if unsat > 0:\n                        logging.warning(\"There are \" + str(unsat) + \" unsatisfiabiable classes.\")\n            except:\n                logging.info(\"Classifying with Pellet failed.\")\n\n        elif reasoner==Reasoner.HERMIT:\n\n                try:\n                    with self.onto:  #it does add inferences to ontology\n\n                        logging.info(\"Classifying ontology with HermiT...\")\n                        sync_reasoner() #HermiT doe snot work very well....\n\n                        unsat = len(list(self.onto.inconsistent_classes()))\n                        logging.info(\"Ontology successfully classified.\")\n                        if unsat > 0:\n                            logging.warning(\"There are \" + str(unsat) + \" unsatisfiabiable classes.\")\n\n                except:\n\n                    logging.info(\"Classifying with HermiT failed.\")\n\n        ##End Classification\n        ####\n\n        #report problem with unsat (Nothing not declared....)\n        #print(list(self.onto.inconsistent_classes()))\n\n        self.graph = default_world.as_rdflib_graph()\n        logging.info(\"There are {} triples in the ontology\".format(len(self.graph)))\n        #self.graph = self.world.as_rdflib_graph()\n\n    def getOntology(self):\n        return self.onto\n\n    def getClassByURI(self, uri):\n        for cls in list(self.getOntology().classes()):\n            if (cls.iri==uri):\n                return cls\n        return None\n\n    def getClassByName(self, name):\n        for cls in list(self.getOntology().classes()):\n            if (cls.name.lower()==name.lower()):\n                return cls\n        return None\n\n    def getEntityByURI(self, uri):\n        for cls in list(self.getOntology().classes()):\n            if (cls.iri==uri):\n                return cls\n        for prop in list(self.getOntology().properties()):\n            if (prop.iri==uri):\n                return prop\n        return None\n\n    def getEntityByName(self, name):\n        for cls in list(self.getOntology().classes()):\n            if (cls.name.lower()==name.lower()):\n                return cls\n        for prop in list(self.getOntology().properties()):\n            if (prop.name.lower()==name.lower()):\n                return prop\n        return None\n\n    def getClassObjectsContainingName(self, name):\n        classes = []\n        for cls in list(self.getOntology().classes()):\n            if (name.lower() in cls.name.lower()):\n                classes.append(cls)\n        return classes\n\n    def getClassIRIsContainingName(self, name):\n        classes = []\n        for cls in list(self.getOntology().classes()):\n            if (name.lower() in cls.name.lower()):\n                classes.append(cls.iri)\n        return classes\n\n    def getAncestorsURIsMinusClass(self,cls):\n        ancestors_str = self.getAncestorsURIs(cls)\n        ancestors_str.remove(cls.iri)\n        return ancestors_str\n\n    def getAncestorsURIs(self,cls):\n        ancestors_str = set()\n        for anc_cls in cls.ancestors():\n            ancestors_str.add(anc_cls.iri)\n        return ancestors_str\n\n    def getAncestorsNames(self,cls):\n        ancestors_str = set()\n        for anc_cls in cls.ancestors():\n            ancestors_str.add(anc_cls.name)\n        return ancestors_str\n\n    def getDescendantURIs(self,cls):\n        descendants_str = set()\n        for desc_cls in cls.descendants():\n            descendants_str.add(desc_cls.iri)\n        return descendants_str\n\n    def getDescendantNames(self,cls):\n        descendants_str = set()\n        for desc_cls in cls.descendants():\n            descendants_str.add(desc_cls.name)\n        return descendants_str\n\n    def getDescendantNamesForClassName(self, cls_name):\n        cls = self.getClassByName(cls_name)\n        descendants_str = set()\n        for desc_cls in cls.descendants():\n            descendants_str.add(desc_cls.name)\n        return descendants_str\n\n    def isSubClassOf(self, sub_cls1, sup_cls2):\n        if sup_cls2 in sub_cls1.ancestors():\n            return True\n        return False\n\n    def isSuperClassOf(self, sup_cls1, sub_cls2):\n        if sup_cls1 in sub_cls2.ancestors():\n            return True\n        return False\n\n    def getDomainURIs(self, prop):\n        domain_uris = set()\n        for cls in prop.domain:\n            #for c in cls.Classes:\n            #    print(c)\n            try:\n                domain_uris.add(cls.iri)\n            except AttributeError:\n                pass\n        return domain_uris\n\n    def getDatatypeRangeNames(self, prop):\n        range_uris = set()\n        for cls in prop.range:\n            range_uris.add(cls.name)  #datatypes are returned without uri\n        return range_uris\n\n    #Only for object properties\n    def getRangeURIs(self, prop):\n        range_uris = set()\n        for cls in prop.range:\n            try:\n                range_uris.add(cls.iri)\n            except AttributeError:\n                pass\n        return range_uris\n\n    def getInverses(self, prop):\n        inv_uris = set()\n        for p in prop.inverse:\n            inv_uris.add(p.iri)\n        return inv_uris\n\n    def getClasses(self):\n        return self.getOntology().classes()\n\n    def getDataProperties(self):\n        return self.getOntology().data_properties()\n\n    def getObjectProperties(self):\n        return self.getOntology().object_properties()\n\n    def getIndividuals(self):\n        return self.getOntology().individuals()\n\n    def getGraph(self):\n        return self.graph\n\n    def queryGraph(self, query):\n        results = self.graph.query(query)\n        return list(results)\n\n    def getQueryForAnnotations(self, ann_prop_uri):\n        return \"\"\"SELECT DISTINCT ?s ?o WHERE {{\n        {{\n        ?s <{ann_prop}> ?o .\n        }}\n        UNION\n        {{\n        ?s <{ann_prop}> ?i .\n        ?i <http://www.w3.org/2000/01/rdf-schema#label> ?o .\n        }}\n        }}\"\"\".format(ann_prop=ann_prop_uri)\n\n    def indexAnnotations(self):\n        annotation_uris = AnnotationURIs()\n        self.entityToSynonyms = {}\n        self.allEntityAnnotations = {}\n        self.preferredLabels = {}\n        self.populateAnnotationDicts(annotation_uris.getAnnotationURIsForSymnonyms(), self.entityToSynonyms)\n        self.populateAnnotationDicts(annotation_uris.getAnnotationURIsForLexicalAnnotations(), self.allEntityAnnotations)\n        self.populateAnnotationDicts(annotation_uris.getAnnotationURIsForPreferredLabels(), self.preferredLabels)\n\n        \n    def populateAnnotationDicts(self, annotation_uris, dictionary):\n        for ann_prop_uri in annotation_uris:\n            results = self.queryGraph(self.getQueryForAnnotations(ann_prop_uri))\n            for row in results:\n                try:\n                    if row[1].language==\"en\" or row[1].language==None:\n                        if not str(row[0]) in dictionary:\n                            dictionary[str(row[0])]=set()\n                        dictionary[str(row[0])].add(row[1].value)\n                except AttributeError:\n                    pass\n        return None\n\n    def getSynonymsNames(self, entity):\n        if entity.iri not in self.entityToSynonyms: \n            return {}\n        return self.entityToSynonyms[entity.iri]\n\n    def getAnnotationNames(self, entity):\n        if entity.iri not in self.allEntityAnnotations: \n            return {}\n        return self.allEntityAnnotations[entity.iri]\n\n    def getPrefferedLabels(self, entity):\n        if entity.iri not in self.preferredLabels: \n            return {}\n        return self.preferredLabels[entity.iri]\n        \n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:32:25.623806Z","iopub.execute_input":"2024-11-06T09:32:25.624114Z","iopub.status.idle":"2024-11-06T09:32:25.666660Z","shell.execute_reply.started":"2024-11-06T09:32:25.624083Z","shell.execute_reply":"2024-11-06T09:32:25.665867Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"%%capture\n!mkdir /kaggle/working/rai-bioml-2024/; cp -r /kaggle/input/\"d/dmshums/rai-bioml-2024\"/* /kaggle/working/rai-bioml-2024/","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:32:25.667786Z","iopub.execute_input":"2024-11-06T09:32:25.668123Z","iopub.status.idle":"2024-11-06T09:32:30.209858Z","shell.execute_reply.started":"2024-11-06T09:32:25.668087Z","shell.execute_reply":"2024-11-06T09:32:30.208679Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"# ontology_path = '/kaggle/input/rai-bioml-2024/omim-ordo/omim.owl'\nontology_path = '/kaggle/working/rai-bioml-2024/omim-ordo/omim-ordo/omim.owl'\n\nonto = OntologyAccess(ontology_path)\nonto.loadOntology()\nonto.indexAnnotations()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:32:30.211670Z","iopub.execute_input":"2024-11-06T09:32:30.212634Z","iopub.status.idle":"2024-11-06T09:33:20.793852Z","shell.execute_reply.started":"2024-11-06T09:32:30.212563Z","shell.execute_reply":"2024-11-06T09:33:20.792858Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"onto_classes = [x for x in onto.getClasses()]\nprint(onto_classes[:25])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:33:20.795160Z","iopub.execute_input":"2024-11-06T09:33:20.795484Z","iopub.status.idle":"2024-11-06T09:33:21.446603Z","shell.execute_reply.started":"2024-11-06T09:33:20.795449Z","shell.execute_reply":"2024-11-06T09:33:21.445635Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[entry.100050, entry.100070, phenotypicSeries.PS100070, entry.100100, entry.100200, entry.100300, phenotypicSeries.PS100300, entry.100600, entry.100700, entry.100800, entry.100820, entry.101000, entry.101120, entry.101200, entry.101400, entry.101600, entry.101800, phenotypicSeries.PS101800, entry.101805, entry.101840, entry.101850, entry.101900, entry.102000, entry.102100, entry.102150]\n","output_type":"stream"}]},{"cell_type":"code","source":"ancestors = {x:values for x in onto.getClasses() if len(values:=onto.getAncestorsNames(x))>3}\ndict(list(ancestors.items())[:10])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:33:21.450323Z","iopub.execute_input":"2024-11-06T09:33:21.450677Z","iopub.status.idle":"2024-11-06T09:33:21.761194Z","shell.execute_reply.started":"2024-11-06T09:33:21.450640Z","shell.execute_reply":"2024-11-06T09:33:21.760244Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{entry.105550: {'105550', 'PS105400', 'PS105550', 'Thing'},\n entry.113750: {'113750', 'PS203100', 'PS227220', 'Thing'},\n entry.128200: {'128200', 'PS128100', 'PS128200', 'Thing'},\n entry.135900: {'135900', 'PS135900', 'PS156200', 'Thing'},\n entry.158810: {'158810', 'PS158810', 'PS603511', 'Thing'},\n entry.183090: {'183090', 'PS105400', 'PS164400', 'Thing'},\n entry.215100: {'215100', 'PS214100', 'PS215100', 'Thing'},\n entry.219200: {'219200', 'PS123700', 'PS212065', 'Thing'},\n entry.229200: {'229200', 'PS130000', 'PS229200', 'Thing'},\n entry.254090: {'254090', 'PS253600', 'PS254090', 'Thing'}}"},"metadata":{}}]},{"cell_type":"code","source":"descendants = {x: values for x in onto.getClasses() if len(values:=onto.getDescendantNames(x)) > 2}\ndict(list(descendants.items())[:10])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:33:21.762306Z","iopub.execute_input":"2024-11-06T09:33:21.762670Z","iopub.status.idle":"2024-11-06T09:33:21.947476Z","shell.execute_reply.started":"2024-11-06T09:33:21.762635Z","shell.execute_reply":"2024-11-06T09:33:21.946574Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{phenotypicSeries.PS100070: {'100070',\n  '609782',\n  '611891',\n  '614375',\n  'PS100070'},\n phenotypicSeries.PS100300: {'100300',\n  '614219',\n  '614814',\n  '615297',\n  '616028',\n  '616589',\n  'PS100300'},\n phenotypicSeries.PS101800: {'101800', '614613', 'PS101800'},\n phenotypicSeries.PS102200: {'102200',\n  '219090',\n  '300943',\n  '617540',\n  '617686',\n  'PS102200'},\n phenotypicSeries.PS102300: {'102300',\n  '608831',\n  '610438',\n  '610439',\n  '611185',\n  '611242',\n  '612853',\n  '615197',\n  'PS102300'},\n phenotypicSeries.PS258150: {'102530',\n  '108420',\n  '243060',\n  '258150',\n  '270960',\n  '301059',\n  '305700',\n  '309120',\n  '400042',\n  '415000',\n  '606766',\n  '612997',\n  '613957',\n  '613958',\n  '614822',\n  '615081',\n  '615413',\n  '615841',\n  '615842',\n  '616950',\n  '617187',\n  '617214',\n  '617576',\n  '617592',\n  '617593',\n  '617644',\n  '617706',\n  '617707',\n  '617959',\n  '617960',\n  '617961',\n  '617965',\n  '618086',\n  '618091',\n  '618110',\n  '618112',\n  '618115',\n  '618152',\n  '618153',\n  '618341',\n  '618420',\n  '618429',\n  '618433',\n  '618643',\n  '618664',\n  '618670',\n  '618745',\n  '618751',\n  '619044',\n  '619094',\n  '619095',\n  '619102',\n  '619108',\n  '619144',\n  '619145',\n  '619177',\n  '619202',\n  '619258',\n  '619379',\n  '619380',\n  '619515',\n  '619528',\n  '619585',\n  '619645',\n  '619646',\n  '619672',\n  '619673',\n  '619689',\n  '619696',\n  '619712',\n  'PS258150'},\n phenotypicSeries.PS103900: {'103900',\n  '605635',\n  '613677',\n  '617027',\n  'PS103900'},\n phenotypicSeries.PS203655: {'104000',\n  '104110',\n  '109200',\n  '203655',\n  '300042',\n  '300710',\n  '610753',\n  '612421',\n  'PS203655'},\n phenotypicSeries.PS301050: {'104200', '203780', '301050', 'PS301050'},\n phenotypicSeries.PS104290: {'104290', '614820', 'PS104290'}}"},"metadata":{}}]},{"cell_type":"code","source":"synonyms = {x:values for x in onto.getClasses() if len(values:=onto.getSynonymsNames(x))>0}\ndict(list(synonyms.items())[:10])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:33:21.948899Z","iopub.execute_input":"2024-11-06T09:33:21.949198Z","iopub.status.idle":"2024-11-06T09:33:22.006300Z","shell.execute_reply.started":"2024-11-06T09:33:21.949165Z","shell.execute_reply":"2024-11-06T09:33:22.005436Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{entry.100070: {'AAA1'},\n entry.100100: {'PBS'},\n entry.100300: {'AOS1'},\n entry.100800: {'ACH'},\n entry.101000: {'NF2'},\n entry.101400: {'SCS'},\n entry.101800: {'ACRDYS1'},\n entry.101850: {'PPKP3'},\n entry.101900: {'AKV'},\n entry.102200: {'PITA1'}}"},"metadata":{}}]},{"cell_type":"code","source":"annotation_labels = {x:values for x in onto.getClasses() if len(values:=onto.getAnnotationNames(x))>1}\ndict(list(annotation_labels.items())[:10])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:33:22.007479Z","iopub.execute_input":"2024-11-06T09:33:22.007910Z","iopub.status.idle":"2024-11-06T09:33:22.068792Z","shell.execute_reply.started":"2024-11-06T09:33:22.007865Z","shell.execute_reply":"2024-11-06T09:33:22.067891Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{entry.100070: {'AAA1', 'aortic aneurysm, familial abdominal, 1'},\n entry.100100: {'PBS', 'prune belly syndrome'},\n entry.100300: {'AOS1', 'adams-oliver syndrome 1'},\n entry.100800: {'ACH', 'achondroplasia'},\n entry.101000: {'NF2', 'neurofibromatosis,  iia 2'},\n entry.101400: {'SCS', 'saethre-chotzen syndrome'},\n entry.101800: {'ACRDYS1',\n  'acrodysostosis 1 with or without hormone resistance'},\n entry.101850: {'PPKP3', 'palmoplantar keratoderma, punctate  iia 3'},\n entry.101900: {'AKV', 'acrokeratosis verruciformis'},\n entry.102200: {'PITA1', 'pituitary adenoma 1, multiple types'}}"},"metadata":{}}]},{"cell_type":"code","source":"annotation_labels = {x:values for x in onto.getClasses() if len(values:=onto.getAnnotationNames(x))>1}\ndict(list(annotation_labels.items())[:10])","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:33:22.069938Z","iopub.execute_input":"2024-11-06T09:33:22.070307Z","iopub.status.idle":"2024-11-06T09:33:22.129301Z","shell.execute_reply.started":"2024-11-06T09:33:22.070265Z","shell.execute_reply":"2024-11-06T09:33:22.128131Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{entry.100070: {'AAA1', 'aortic aneurysm, familial abdominal, 1'},\n entry.100100: {'PBS', 'prune belly syndrome'},\n entry.100300: {'AOS1', 'adams-oliver syndrome 1'},\n entry.100800: {'ACH', 'achondroplasia'},\n entry.101000: {'NF2', 'neurofibromatosis,  iia 2'},\n entry.101400: {'SCS', 'saethre-chotzen syndrome'},\n entry.101800: {'ACRDYS1',\n  'acrodysostosis 1 with or without hormone resistance'},\n entry.101850: {'PPKP3', 'palmoplantar keratoderma, punctate  iia 3'},\n entry.101900: {'AKV', 'acrokeratosis verruciformis'},\n entry.102200: {'PITA1', 'pituitary adenoma 1, multiple types'}}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Prompting","metadata":{}},{"cell_type":"code","source":"class OntologyEntryAttr:\n    def __init__(self, class_id, onto=None):\n        self.class_id = class_id\n        self.annotation = {'class_id':class_id}\n        if onto is not None:\n            self.annotateEntry(onto)\n\n    def annotateEntry(self, onto):\n        self.annotation['synonyms'] = onto.getSynonymsNames(self.class_id)\n        self.annotation['names'] = onto.getAnnotationNames(self.class_id)\n        self.annotation['children'] = onto.getDescendantNames(self.class_id)\n        self.annotation['parents'] = onto.getAncestorsNames(self.class_id)\n\n    def getAllNames(self):\n        return self.annotation['names']\n    def getSynonyms(self):\n        return self.annotation['synonyms']\n    def getChildren(self):\n        return self.annotation['children']\n    def getParents(self):\n        return self.annotation['parents']\n    def __repr__(self):\n        return str(annotation)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:33:22.130455Z","iopub.execute_input":"2024-11-06T09:33:22.130771Z","iopub.status.idle":"2024-11-06T09:33:22.138946Z","shell.execute_reply.started":"2024-11-06T09:33:22.130738Z","shell.execute_reply":"2024-11-06T09:33:22.138012Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def composePrompt(source_entry:OntologyEntryAttr, target_entry:OntologyEntryAttr, onto=None):\n    source_entry = OntologyEntryAttr(onto.getClassByURI(source_entry), onto)\n    target_entry = OntologyEntryAttr(onto.getClassByURI(target_entry), onto)\n    return f\"\"\"\n**Task Description:**\n\nGiven two sets of concepts with their names, parent relationships, and child relationships, determine if these concepts are identical. Evaluate based on the provided names and hierarchical structures.\n\n**Template for Alignment:**\n\n1. **Source Concept:**\n\n**Names:** [List of source concept names]\n\n**Parent Concepts:** [List of source concept's parent names]\n\n**Child Concepts:** [List of source concept's child names]\n\n2. **Target Concept:**\n\n**Names:** [List of target concept names]\n\n**Parent Concepts:** [List of target concept's parent names]\n\n**Child Concepts:** [List of target concept's child names]\n\n**Determine Concept Equivalence:**\n\nAnalyze whether the source and target concepts are equivalent based on names, parent concepts, and child concepts. Provide your conclusion (\"Yes\" for identical, \"No\" for different).\n\n**Example Prompts (Few-Shot Examples):**\n\n1. **Example 1:**\n\nSource Concept Names: [e.g., \"Entity_A\"]\n\nParent of Source Concept: [e.g., \"Parent_A\"]\n\nChild of Source Concept: [e.g., \"Child_A\"]\n\nTarget Concept Names: [e.g., \"Entity_B\"]\n\nParent of Target Concept: [e.g., \"Parent_B\"]\n\nChild of Target Concept: [e.g., \"Child_B\"]\n\n**Conclusion:** No\n\n2. **Example 2:**\n\nSource Concept Names: [e.g., \"Entity_X\"]\n\nParent of Source Concept: [e.g., \"Parent_X\"]\n\nChild of Source Concept: [e.g., \"Child_X\"]\n\nTarget Concept Names: [e.g., \"Entity_X\"]\n\nParent of Target Concept: [e.g., \"Parent_X\"]\n\nChild of Target Concept: [e.g., \"Child_X\"]\n\n**Conclusion:** Yes\n\n**Now Answer:**\n\nSource Concept Names: {source_entry.getAllNames()}\n\nParent of Source Concept: {source_entry.getParents()}\n\nChild of Source Concept: {source_entry.getChildren()}\n\nTarget Concept Names: {target_entry.getAllNames()}\n\nParent of Target Concept: {target_entry.getParents()}\n\nChild of Target Concept: {target_entry.getChildren()}\n    \"\"\"\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:33:22.140154Z","iopub.execute_input":"2024-11-06T09:33:22.140434Z","iopub.status.idle":"2024-11-06T09:33:22.151294Z","shell.execute_reply.started":"2024-11-06T09:33:22.140402Z","shell.execute_reply":"2024-11-06T09:33:22.150444Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"source_entity = 'http://omim.org/entry/100070'\ntarget_entity = 'http://omim.org/entry/101900'\ndemo_prompt = composePrompt(source_entity, target_entity, onto)\nprint(demo_prompt)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:33:22.152535Z","iopub.execute_input":"2024-11-06T09:33:22.152999Z","iopub.status.idle":"2024-11-06T09:33:22.202987Z","shell.execute_reply.started":"2024-11-06T09:33:22.152956Z","shell.execute_reply":"2024-11-06T09:33:22.202123Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\n**Task Description:**\n\nGiven two sets of concepts with their names, parent relationships, and child relationships, determine if these concepts are identical. Evaluate based on the provided names and hierarchical structures.\n\n**Template for Alignment:**\n\n1. **Source Concept:**\n\n**Names:** [List of source concept names]\n\n**Parent Concepts:** [List of source concept's parent names]\n\n**Child Concepts:** [List of source concept's child names]\n\n2. **Target Concept:**\n\n**Names:** [List of target concept names]\n\n**Parent Concepts:** [List of target concept's parent names]\n\n**Child Concepts:** [List of target concept's child names]\n\n**Determine Concept Equivalence:**\n\nAnalyze whether the source and target concepts are equivalent based on names, parent concepts, and child concepts. Provide your conclusion (\"Yes\" for identical, \"No\" for different).\n\n**Example Prompts (Few-Shot Examples):**\n\n1. **Example 1:**\n\nSource Concept Names: [e.g., \"Entity_A\"]\n\nParent of Source Concept: [e.g., \"Parent_A\"]\n\nChild of Source Concept: [e.g., \"Child_A\"]\n\nTarget Concept Names: [e.g., \"Entity_B\"]\n\nParent of Target Concept: [e.g., \"Parent_B\"]\n\nChild of Target Concept: [e.g., \"Child_B\"]\n\n**Conclusion:** No\n\n2. **Example 2:**\n\nSource Concept Names: [e.g., \"Entity_X\"]\n\nParent of Source Concept: [e.g., \"Parent_X\"]\n\nChild of Source Concept: [e.g., \"Child_X\"]\n\nTarget Concept Names: [e.g., \"Entity_X\"]\n\nParent of Target Concept: [e.g., \"Parent_X\"]\n\nChild of Target Concept: [e.g., \"Child_X\"]\n\n**Conclusion:** Yes\n\n**Now Answer:**\n\nSource Concept Names: {'aortic aneurysm, familial abdominal, 1', 'AAA1'}\n\nParent of Source Concept: {'Thing', '100070', 'PS100070'}\n\nChild of Source Concept: {'100070'}\n\nTarget Concept Names: {'AKV', 'acrokeratosis verruciformis'}\n\nParent of Target Concept: {'101900', 'Thing'}\n\nChild of Target Concept: {'101900'}\n    \n","output_type":"stream"}]},{"cell_type":"code","source":"print(mistral.ask_question(demo_prompt))\nprint(mistral.ask_question('Explain the last answer'))","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:33:22.204307Z","iopub.execute_input":"2024-11-06T09:33:22.204809Z","iopub.status.idle":"2024-11-06T09:33:49.802692Z","shell.execute_reply.started":"2024-11-06T09:33:22.204767Z","shell.execute_reply":"2024-11-06T09:33:49.801636Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"**Conclusion:** No\n\nThe source concept and the target concept are not identical. The source concept is related to 'aortic aneurysm, familial abdominal, 1' and 'AAA1', while the target concept is 'AKV' and 'acrokeratosis verruciformis'. Additionally, the parent concepts and child concepts for each concept are different. The source concept has parent concepts 'Thing', '100070', and 'PS100070', and a child concept '100070'. The target concept has parent concepts '101900' and 'Thing', and a child concept '101900'.\nGreetings, I am Megatron, the mighty Decepticon leader. In the last response, I was explaining the concept of a \"recursive function\" in programming.\n\nA recursive function is a self-replicating function that solves a problem by breaking it down into smaller, simpler sub-problems of the same type. Instead of using loops or other control structures, a recursive function calls itself repeatedly, each time with a smaller input until it reaches a base case, which is a simple enough problem that can be solved directly without further recursion.\n\nFor example, let's consider the factorial function, which calculates the product of all positive integers up to a given number. A recursive implementation of this function would look like this:\n\n```\ndef factorial(n):\n    if n == 0:\n        return 1\n    else:\n        return n * factorial(n-1)\n```\n\nIn this function, the base case is when `n` equals 0, and the recursive case is when `n` is greater than 0. The function calls itself with a smaller input (`n-1`) until it reaches the base case, at which point it returns the product of all the numbers from 1 to `n`.\n\nRecursive functions can be powerful tools for solving complex problems, but they can also be less efficient than iterative solutions due to the overhead of function calls and the potential for stack overflow if the recursion depth is too great. However, in many cases, recursive functions are easier to understand and write, making them a valuable addition to any programmer's toolkit.\n","output_type":"stream"}]},{"cell_type":"code","source":"mistral = Server()\nmistral.add_system_context(\"Answer as a Knowledge storage utility\")\nprint(mistral.ask_question(demo_prompt))\nprint(mistral.ask_question('Explain the last answer'))","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:20:11.671665Z","iopub.execute_input":"2024-11-06T09:20:11.672081Z","iopub.status.idle":"2024-11-06T09:20:13.262269Z","shell.execute_reply.started":"2024-11-06T09:20:11.672044Z","shell.execute_reply":"2024-11-06T09:20:13.260824Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c904ea2a5594c5db5d0de3fde75b50a"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mistral \u001b[38;5;241m=\u001b[39m \u001b[43mServer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m mistral\u001b[38;5;241m.\u001b[39madd_system_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer as a Knowledge storage utility\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(mistral\u001b[38;5;241m.\u001b[39mask_question(demo_prompt))\n","Cell \u001b[0;32mIn[2], line 14\u001b[0m, in \u001b[0;36mServer.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_context \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4014\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4004\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4005\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4007\u001b[0m     (\n\u001b[1;32m   4008\u001b[0m         model,\n\u001b[1;32m   4009\u001b[0m         missing_keys,\n\u001b[1;32m   4010\u001b[0m         unexpected_keys,\n\u001b[1;32m   4011\u001b[0m         mismatched_keys,\n\u001b[1;32m   4012\u001b[0m         offload_index,\n\u001b[1;32m   4013\u001b[0m         error_msgs,\n\u001b[0;32m-> 4014\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4021\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4022\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4025\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4026\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4031\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4033\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4034\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4502\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4498\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4499\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4500\u001b[0m                 )\n\u001b[1;32m   4501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4502\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4503\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4504\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4505\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4506\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4507\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4508\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4509\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4510\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4511\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4512\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4513\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4514\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4515\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4516\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4517\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4518\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4520\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:973\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    970\u001b[0m         param_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 973\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    975\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py:416\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    414\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 416\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 61.12 MiB is free. Process 2796 has 15.83 GiB memory in use. Of the allocated memory 15.38 GiB is allocated by PyTorch, and 157.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 61.12 MiB is free. Process 2796 has 15.83 GiB memory in use. Of the allocated memory 15.38 GiB is allocated by PyTorch, and 157.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}]},{"cell_type":"markdown","source":"# Local matching","metadata":{}},{"cell_type":"code","source":"%%capture\n!mkdir /kaggle/working/rai-bioml-2024/; cp -r /kaggle/input/\"d/dmshums/rai-bioml-2024\"/* /kaggle/working/rai-bioml-2024/","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:59:39.687771Z","iopub.execute_input":"2024-11-08T09:59:39.688477Z","iopub.status.idle":"2024-11-08T09:59:47.210288Z","shell.execute_reply.started":"2024-11-08T09:59:39.688431Z","shell.execute_reply":"2024-11-08T09:59:47.209011Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-11-08T10:03:46.371610Z","iopub.execute_input":"2024-11-08T10:03:46.372230Z","iopub.status.idle":"2024-11-08T10:03:46.784918Z","shell.execute_reply.started":"2024-11-08T10:03:46.372189Z","shell.execute_reply":"2024-11-08T10:03:46.784125Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"test_candidates_path = \"/kaggle/working/rai-bioml-2024/omim-ordo/omim-ordo/refs_equiv/test.cands.tsv\"","metadata":{"execution":{"iopub.status.busy":"2024-11-08T10:03:47.090246Z","iopub.execute_input":"2024-11-08T10:03:47.091118Z","iopub.status.idle":"2024-11-08T10:03:47.095190Z","shell.execute_reply.started":"2024-11-08T10:03:47.091076Z","shell.execute_reply":"2024-11-08T10:03:47.094245Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test_candidates = pd.read_csv(test_candidates_path, sep='\\t')\ntest_candidates.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-08T10:03:47.674520Z","iopub.execute_input":"2024-11-08T10:03:47.675318Z","iopub.status.idle":"2024-11-08T10:03:47.815432Z","shell.execute_reply.started":"2024-11-08T10:03:47.675274Z","shell.execute_reply":"2024-11-08T10:03:47.814445Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                       SrcEntity  \\\n0  http://www.omim.org/phenotypicSeries/PS309510   \n1                   http://omim.org/entry/615075   \n2                   http://omim.org/entry/613724   \n3                   http://omim.org/entry/602066   \n4                   http://omim.org/entry/167730   \n\n                                   TgtEntity  \\\n0   http://www.orpha.net/ORDO/Orphanet_98464   \n1  http://www.orpha.net/ORDO/Orphanet_404473   \n2  http://www.orpha.net/ORDO/Orphanet_163684   \n3   http://www.orpha.net/ORDO/Orphanet_31709   \n4    http://www.orpha.net/ORDO/Orphanet_2399   \n\n                                       TgtCandidates  \n0  ('http://www.orpha.net/ORDO/Orphanet_93406', '...  \n1  ('http://www.orpha.net/ORDO/Orphanet_157791', ...  \n2  ('http://www.orpha.net/ORDO/Orphanet_639', 'ht...  \n3  ('http://www.orpha.net/ORDO/Orphanet_99141', '...  \n4  ('http://www.orpha.net/ORDO/Orphanet_1475', 'h...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SrcEntity</th>\n      <th>TgtEntity</th>\n      <th>TgtCandidates</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n      <td>http://www.orpha.net/ORDO/Orphanet_98464</td>\n      <td>('http://www.orpha.net/ORDO/Orphanet_93406', '...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://omim.org/entry/615075</td>\n      <td>http://www.orpha.net/ORDO/Orphanet_404473</td>\n      <td>('http://www.orpha.net/ORDO/Orphanet_157791', ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://omim.org/entry/613724</td>\n      <td>http://www.orpha.net/ORDO/Orphanet_163684</td>\n      <td>('http://www.orpha.net/ORDO/Orphanet_639', 'ht...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://omim.org/entry/602066</td>\n      <td>http://www.orpha.net/ORDO/Orphanet_31709</td>\n      <td>('http://www.orpha.net/ORDO/Orphanet_99141', '...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://omim.org/entry/167730</td>\n      <td>http://www.orpha.net/ORDO/Orphanet_2399</td>\n      <td>('http://www.orpha.net/ORDO/Orphanet_1475', 'h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def implication_prompt(source_entry, target_entry):\n    \"\"\"\n    Creates a prompt asking if 'source_entry' implies 'target_entry'.\n    Example: \"It is [a/an] C, is it a D? Yes/No\"\n    \"\"\"\n    return f\"It is [a/an] ${source_entry}$, is it a ${target_entry}$? Yes/No\"\n\ndef equivalence_prompt(source_entry, target_entry):\n    \"\"\"\n    Creates prompts for both directions to check if 'source_entry' implies 'target_entry' and vice versa.\n    - Example: \"It is [a/an] C, is it a D? Yes/No\"\n    - Example: \"It is [a/an] D, is it a C? Yes/No\"\n    \"\"\"\n    prompt1 = implication_prompt(source_entry, target_entry)\n    prompt2 = implication_prompt(target_entry, source_entry)\n    return prompt1, prompt2\n\ndef synonyms_prompt(source_label, target_label):\n    \"\"\"\n    Uses ontology to create prompts involving synonyms for C and D.\n    Example: \"It is [a/an] C-label2, is it a D-label3? Yes/No\"\n    \"\"\"\n    return f\"It is [a/an] ${source_label}$, is it a ${target_label}$? Yes/No\"\n\ndef transitivity_prompt(source_entry, intermediate_entry, target_entry):\n    \"\"\"\n    Creates a transitivity prompt to check if 'source_entry' implies an intermediate entry,\n    which then implies 'target_entry'.\n    \"\"\"\n    return f\"It is [a/an] ${source_entry}$, implies ${intermediate_entry}$, implies ${target_entry}$? Yes/No\"\n\ndef hierarchical_equivalence_prompt(child1, parent1, child2, parent2):\n    \"\"\"\n    Creates prompts to check bidirectional equivalence between two hierarchical entries.\n    Example:\n    - \"Something is [a/an] C and [a/an] C', is it also [a/an] D and [a/an] D'? Yes/No\"\n    - \"Something is [a/an] D and [a/an] D', is it also [a/an] C and [a/an] C'? Yes/No\"\n    \"\"\"\n    prompt1 = f\"Something is [a/an] ${child1}$ and [a/an] ${parent1}$, is it also [a/an] ${child2}$ and [a/an] ${parent2}$? Yes/No\"\n    prompt2 = f\"Something is [a/an] ${child2}$ and [a/an] ${parent2}$, is it also [a/an] ${child1}$ and [a/an] ${parent1}$? Yes/No\"\n    return prompt1, prompt2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def local_matching_confidence(source_entry, target_entry, onto=None):\n    source_attr = OntologyEntryAttr(onto.getClassByURI(source_entry), onto)\n    target_attr = OntologyEntryAttr(onto.getClassByURI(target_entry), onto)\n\n    general_points = 0\n    retrieved_points = 0\n\n    # compare names\n    for s in source_attr.getAllNames():\n        for t in target_attr.getAllNames():\n            e1, e2 = equivalence_prompt(s, t)\n            q1 = mistral.ask_question(e1)\n            q2 = mistral.ask_question(e2)\n            if q1 == \"Yes\":\n                retrieved_points += 1\n            if q2 == \"Yes\":\n                retrieved_points += 1\n            if q1 == \"Yes\" and q2 == \"Yes\":\n                retrieved_points += 1\n            general_points += 3\n\n    # compare synonyms\n    for s in source_attr.getSynonyms():\n        for t in target_attr.getSynonyms():\n            e = synonyms_prompt(s, t)\n            q = mistral.ask_question(e)\n            if q == \"Yes\":\n                retrieved_points += 1\n            general_points += 1\n\n    # compare hierarchy\n    for schild in source_attr.getChildren():\n        for tchild in target_attr.getChildren():\n            for sparent in source_attr.getParents():\n                for tparent in target_attr.getParents():\n                    e1, e2 = hierarchical_equivalence_prompt(schild, sparent, tchild, tparent)\n                    q1 = mistral.ask_question(e1)\n                    q2 = mistral.ask_question(e2)\n                    if q1 == \"Yes\":\n                        retrieved_points += 1\n                    if q2 == \"Yes\":\n                        retrieved_points += 1\n                    if q1 == \"Yes\" and q2 == \"Yes\":\n                        retrieved_points += 1\n                    general_points += 3\n\n    confidence = retrieved_points / general_points\n    return confidence","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidences = {}\n\nfor row in test_candidates:\n    source = row[0]\n    target = row[1]\n    confidences[(source, target)] = []\n    for candidate in row[2]:\n        confidence = local_matching_confidence(source, candidate)\n        confidences[(source, target)].append((candidate, confidence))","metadata":{},"execution_count":null,"outputs":[]}]}