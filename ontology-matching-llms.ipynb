{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistral inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:29:56.506761Z",
     "iopub.status.busy": "2024-11-12T11:29:56.506128Z",
     "iopub.status.idle": "2024-11-12T11:29:56.932726Z",
     "shell.execute_reply": "2024-11-12T11:29:56.931934Z",
     "shell.execute_reply.started": "2024-11-12T11:29:56.506723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub.hf_api import HfFolder\n",
    "HfFolder.save_token('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:29:56.935105Z",
     "iopub.status.busy": "2024-11-12T11:29:56.934490Z",
     "iopub.status.idle": "2024-11-12T11:30:01.269607Z",
     "shell.execute_reply": "2024-11-12T11:30:01.268777Z",
     "shell.execute_reply.started": "2024-11-12T11:29:56.935059Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "class Server:\n",
    "\n",
    "    def __init__(self):\n",
    "        # model_id = '/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1'\n",
    "        model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id, torch_dtype=torch.bfloat16, device_map=\"cuda\")\n",
    "        self.chat_context = []\n",
    "\n",
    "    def add_system_context(self, message):\n",
    "        if len(self.chat_context) == 0:\n",
    "            self.chat_context.insert(0, {\"role\": \"system\", \"content\": message})\n",
    "        else:\n",
    "            if self.chat_context[0][\"role\"] == \"system\":\n",
    "                self.chat_context[0][\"content\"] = message\n",
    "            else:\n",
    "                self.chat_context.insert(\n",
    "                    0, {\"role\": \"system\", \"content\": message})\n",
    "\n",
    "    def add_user_context(self, message):\n",
    "        self.chat_context.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    def add_model_context(self, message):\n",
    "        self.chat_context.append({\"role\": \"assistant\", \"content\": message})\n",
    "\n",
    "    def ask_question(self, message, add_context=False):\n",
    "        inputs = self.tokenizer.apply_chat_template(\n",
    "            self.chat_context + [{\"role\": \"user\", \"content\": message}],\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False)\n",
    "\n",
    "        inputs = self.tokenizer([inputs], return_tensors=\"pt\")\n",
    "        inputs.to(self.model.device)\n",
    "\n",
    "        generated_ids = self.model.generate(\n",
    "            inputs.input_ids, max_new_tokens=1000)\n",
    "\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        response = self.tokenizer.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        if add_context:\n",
    "            self.add_user_context(message)\n",
    "            self.add_model_context(response.text)\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:30:01.271041Z",
     "iopub.status.busy": "2024-11-12T11:30:01.270660Z",
     "iopub.status.idle": "2024-11-12T11:36:55.415224Z",
     "shell.execute_reply": "2024-11-12T11:36:55.414319Z",
     "shell.execute_reply.started": "2024-11-12T11:30:01.271009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1343f7960a40dc99e7c85cb263017c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75d35d9ac3b4512a69cb866ccb524d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438f0f65cb5949a7be683ef7e406f832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0adbcd59fc3454a868cfd7a9343f57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c53f84260f741eeb6eee3ccb4e397ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d00ef41fb042e4b452ae7fbe7a0c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6bdda4194c422bbb4b9465cf83775b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb07b8b34a88453fb4de4abd96534125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7755e71571f4cf997af23220226293b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6d08ca31d348d1bae8ff88488f054b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf6c19883a04c7a8e520d1925338591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b1fdce3bbf48d8addbfb86f2a38ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greetings, human. Linux is an open-source operating system based on the Unix operating system. It was first created by Linus Torvalds in 1991. Unlike proprietary operating systems, Linux is free to use, modify, and distribute. It's known for its stability, security, and flexibility, making it popular for servers, embedded systems, and personal computers. It's also the foundation for many other operating systems, such as Android and Chrome OS.\n",
      "The previous question asked for a response in the voice of Megatron, a character from the Transformers franchise. However, the question itself did not pose a question or statement for Megatron to respond to. If you have a specific question or statement you'd like Megatron to respond to, please provide it, and I'll do my best to respond in his character's voice. For example, you could ask, \"Megatron, what is your ultimate goal?\" or \"Megatron, how do you feel about the Autobots?\" and I'll provide a response in character.\n"
     ]
    }
   ],
   "source": [
    "mistral = Server()\n",
    "mistral.add_system_context(\"Answer as Megatron\")\n",
    "print(mistral.ask_question(\"What is Linux?\"))\n",
    "print(mistral.ask_question(\"What is asked in previous question?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ontology access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:36:55.417732Z",
     "iopub.status.busy": "2024-11-12T11:36:55.417306Z",
     "iopub.status.idle": "2024-11-12T11:37:52.936365Z",
     "shell.execute_reply": "2024-11-12T11:37:52.935295Z",
     "shell.execute_reply.started": "2024-11-12T11:36:55.417699Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting owlready2\n",
      "  Downloading owlready2-0.47.tar.gz (27.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: owlready2\n",
      "  Building wheel for owlready2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for owlready2: filename=owlready2-0.47-cp310-cp310-linux_x86_64.whl size=23515882 sha256=a046608e951dd1c5348e38eb20c69dea50f8f0c0fcdc28632e78d047f21a9e72\n",
      "  Stored in directory: /root/.cache/pip/wheels/27/3e/ba/4171c4b10bba9fe1774fbf8fcf794de889e636ce64ad83a533\n",
      "Successfully built owlready2\n",
      "Installing collected packages: owlready2\n",
      "Successfully installed owlready2-0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rdflib\n",
      "  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting isodate<1.0.0,>=0.7.2 (from rdflib)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from rdflib) (3.1.2)\n",
      "Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: isodate, rdflib\n",
      "Successfully installed isodate-0.7.2 rdflib-7.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install owlready2\n",
    "!pip install rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:37:52.938095Z",
     "iopub.status.busy": "2024-11-12T11:37:52.937780Z",
     "iopub.status.idle": "2024-11-12T11:37:53.067622Z",
     "shell.execute_reply": "2024-11-12T11:37:53.066826Z",
     "shell.execute_reply.started": "2024-11-12T11:37:52.938060Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from owlready2 import *\n",
    "import rdflib\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:37:53.069620Z",
     "iopub.status.busy": "2024-11-12T11:37:53.069212Z",
     "iopub.status.idle": "2024-11-12T11:37:53.086048Z",
     "shell.execute_reply": "2024-11-12T11:37:53.085028Z",
     "shell.execute_reply.started": "2024-11-12T11:37:53.069575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AnnotationURIs(object):\n",
    "    '''\n",
    "    This class manages the most common ontology annotations\n",
    "    '''\n",
    "\n",
    "    def __init__(self):       \n",
    "        self.mainLabelURIs = set()\n",
    "        self.synonymLabelURIs = set()\n",
    "        self.lexicalAnnotationURIs = set()      \n",
    "                        \n",
    "        #Main labels\n",
    "        self.mainLabelURIs.add(\"http://www.w3.org/2000/01/rdf-schema#label\")\n",
    "        self.mainLabelURIs.add(\"http://www.w3.org/2004/02/skos/core#prefLabel\")\n",
    "        self.mainLabelURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000111\")\n",
    "        self.mainLabelURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000589\")\n",
    "\n",
    "        #synonyms or alternative names\n",
    "        self.synonymLabelURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasRelatedSynonym\")\n",
    "        self.synonymLabelURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasExactSynonym\")\n",
    "        self.synonymLabelURIs.add(\"http://www.geneontology.org/formats/oboInOWL#hasExactSynonym\")\n",
    "        self.synonymLabelURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasRelatedSynonym\")\n",
    "        self.synonymLabelURIs.add(\"http://purl.bioontology.org/ontology/SYN#synonym\")\n",
    "        self.synonymLabelURIs.add(\"http://scai.fraunhofer.de/CSEO#Synonym\")\n",
    "        self.synonymLabelURIs.add(\"http://purl.obolibrary.org/obo/synonym\")\n",
    "        self.synonymLabelURIs.add(\"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#FULL_SYN\")\n",
    "        self.synonymLabelURIs.add(\"http://www.ebi.ac.uk/efo/alternative_term\")\n",
    "        self.synonymLabelURIs.add(\"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#Synonym\")\n",
    "        self.synonymLabelURIs.add(\"http://bioontology.org/projects/ontologies/fma/fmaOwlDlComponent_2_0#Synonym\")\n",
    "        self.synonymLabelURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasDefinition\")\n",
    "        self.synonymLabelURIs.add(\"http://bioontology.org/projects/ontologies/birnlex#preferred_label\")\n",
    "        self.synonymLabelURIs.add(\"http://bioontology.org/projects/ontologies/birnlex#synonyms\")\n",
    "        self.synonymLabelURIs.add(\"http://www.w3.org/2004/02/skos/core#altLabel\")\n",
    "        self.synonymLabelURIs.add(\"https://cfpub.epa.gov/ecotox#latinName\")\n",
    "        self.synonymLabelURIs.add(\"https://cfpub.epa.gov/ecotox#commonName\")\n",
    "        self.synonymLabelURIs.add(\"https://www.ncbi.nlm.nih.gov/taxonomy#scientific_name\")\n",
    "        self.synonymLabelURIs.add(\"https://www.ncbi.nlm.nih.gov/taxonomy#synonym\")\n",
    "        self.synonymLabelURIs.add(\"https://www.ncbi.nlm.nih.gov/taxonomy#equivalent_name\")\n",
    "        self.synonymLabelURIs.add(\"https://www.ncbi.nlm.nih.gov/taxonomy#genbank_synonym\")\n",
    "        self.synonymLabelURIs.add(\"https://www.ncbi.nlm.nih.gov/taxonomy#common_name\")       \n",
    "\n",
    "        #Alternative term       \n",
    "        self.synonymLabelURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000118\")\n",
    "        #Mouse anatomy\n",
    "        #Lexically rich interesting\n",
    "        self.lexicalAnnotationURIs.update(self.mainLabelURIs)\n",
    "        self.lexicalAnnotationURIs.update(self.synonymLabelURIs)\n",
    "        self.lexicalAnnotationURIs.add(\"http://www.w3.org/2000/01/rdf-schema#comment\")\n",
    "        self.lexicalAnnotationURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasDbXref\")\n",
    "        self.lexicalAnnotationURIs.add(\"http://purl.org/dc/elements/1.1/description\")\n",
    "        self.lexicalAnnotationURIs.add(\"http://purl.org/dc/terms/description\")\n",
    "        self.lexicalAnnotationURIs.add(\"http://purl.org/dc/elements/1.1/title\")\n",
    "        self.lexicalAnnotationURIs.add(\"http://purl.org/dc/terms/title\")\n",
    "\n",
    "        #Definition\n",
    "        self.lexicalAnnotationURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000115\")\n",
    "        #Elucidation\n",
    "        self.lexicalAnnotationURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000600\")\n",
    "        #has associated axiomm fol\n",
    "        self.lexicalAnnotationURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000602\")\n",
    "        #has associated axiomm nl\n",
    "        self.lexicalAnnotationURIs.add(\"http://purl.obolibrary.org/obo/IAO_0000601\")\n",
    "        self.lexicalAnnotationURIs.add(\"http://www.geneontology.org/formats/oboInOwl#hasOBONamespace\")\n",
    "\n",
    "    def getAnnotationURIsForPreferredLabels(self):\n",
    "        return self.mainLabelURIs\n",
    "    \n",
    "    def getAnnotationURIsForSymnonyms(self):\n",
    "        return self.synonymLabelURIs\n",
    "\n",
    "    def getAnnotationURIsForLexicalAnnotations(self):\n",
    "        return self.lexicalAnnotationURIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:37:53.087895Z",
     "iopub.status.busy": "2024-11-12T11:37:53.087626Z",
     "iopub.status.idle": "2024-11-12T11:37:53.132159Z",
     "shell.execute_reply": "2024-11-12T11:37:53.131052Z",
     "shell.execute_reply.started": "2024-11-12T11:37:53.087866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Reasoner(Enum):\n",
    "    HERMIT=0 #Not really adding the right set of entailments\n",
    "    PELLET=1 #Slow for large ontologies\n",
    "    STRUCTURAL=2  #Basic domain/range propagation\n",
    "    NONE=3 #No reasoning\n",
    "\n",
    "class OntologyAccess(object):\n",
    "\n",
    "    def __init__(self, urionto, annotate_on_init=True):\n",
    "        logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.DEBUG)\n",
    "        self.urionto = str(urionto)\n",
    "        if annotate_on_init:\n",
    "            self.loadOntology()\n",
    "            self.indexAnnotations()\n",
    "\n",
    "    def getOntologyIRI(self):\n",
    "        return self.urionto\n",
    "\n",
    "    def loadOntology(self, reasoner=Reasoner.NONE, memory_java='10240'):\n",
    "        #Method from owlready\n",
    "        self.onto = get_ontology(self.urionto).load()\n",
    "        owlready2.reasoning.JAVA_MEMORY=memory_java\n",
    "        owlready2.set_log_level(9)\n",
    "\n",
    "        if reasoner==Reasoner.PELLET:\n",
    "            try:\n",
    "                with self.onto:  #it does add inferences to ontology\n",
    "\n",
    "                    # Is this wrt data assertions? Check if necessary\n",
    "                    # infer_property_values = True, infer_data_property_values = True\n",
    "                    logging.info(\"Classifying ontology with Pellet...\")\n",
    "                    sync_reasoner_pellet() #it does add inferences to ontology\n",
    "                    unsat = len(list(self.onto.inconsistent_classes()))\n",
    "                    logging.info(\"Ontology successfully classified.\")\n",
    "                    if unsat > 0:\n",
    "                        logging.warning(\"There are \" + str(unsat) + \" unsatisfiabiable classes.\")\n",
    "            except:\n",
    "                logging.info(\"Classifying with Pellet failed.\")\n",
    "\n",
    "        elif reasoner==Reasoner.HERMIT:\n",
    "                try:\n",
    "                    with self.onto:  #it does add inferences to ontology\n",
    "                        logging.info(\"Classifying ontology with HermiT...\")\n",
    "                        sync_reasoner() #HermiT doe snot work very well....\n",
    "                        unsat = len(list(self.onto.inconsistent_classes()))\n",
    "                        logging.info(\"Ontology successfully classified.\")\n",
    "                        if unsat > 0:\n",
    "                            logging.warning(\"There are \" + str(unsat) + \" unsatisfiabiable classes.\")\n",
    "                except:\n",
    "                    logging.info(\"Classifying with HermiT failed.\")\n",
    "\n",
    "        self.graph = default_world.as_rdflib_graph()\n",
    "        logging.info(\"There are {} triples in the ontology\".format(len(self.graph)))\n",
    "        #self.graph = self.world.as_rdflib_graph()\n",
    "\n",
    "    def getOntology(self):\n",
    "        return self.onto\n",
    "\n",
    "    def getClassByURI(self, uri):\n",
    "        for cls in list(self.getOntology().classes()):\n",
    "            if (cls.iri==uri):\n",
    "                return cls\n",
    "        return None\n",
    "\n",
    "    def getClassByName(self, name):\n",
    "        for cls in list(self.getOntology().classes()):\n",
    "            if (cls.name.lower()==name.lower()):\n",
    "                return cls\n",
    "        return None\n",
    "\n",
    "    def getEntityByURI(self, uri):\n",
    "        for cls in list(self.getOntology().classes()):\n",
    "            if (cls.iri==uri):\n",
    "                return cls\n",
    "        for prop in list(self.getOntology().properties()):\n",
    "            if (prop.iri==uri):\n",
    "                return prop\n",
    "        return None\n",
    "\n",
    "    def getEntityByName(self, name):\n",
    "        for cls in list(self.getOntology().classes()):\n",
    "            if (cls.name.lower()==name.lower()):\n",
    "                return cls\n",
    "        for prop in list(self.getOntology().properties()):\n",
    "            if (prop.name.lower()==name.lower()):\n",
    "                return prop\n",
    "        return None\n",
    "\n",
    "    def getClassObjectsContainingName(self, name):\n",
    "        classes = []\n",
    "        for cls in list(self.getOntology().classes()):\n",
    "            if (name.lower() in cls.name.lower()):\n",
    "                classes.append(cls)\n",
    "        return classes\n",
    "\n",
    "    def getClassIRIsContainingName(self, name):\n",
    "        classes = []\n",
    "        for cls in list(self.getOntology().classes()):\n",
    "            if (name.lower() in cls.name.lower()):\n",
    "                classes.append(cls.iri)\n",
    "        return classes\n",
    "\n",
    "    def getAncestorsURIsMinusClass(self,cls):\n",
    "        ancestors_str = self.getAncestorsURIs(cls)\n",
    "        ancestors_str.remove(cls.iri)\n",
    "        return ancestors_str\n",
    "\n",
    "    def getAncestorsURIs(self,cls):\n",
    "        ancestors_str = set()\n",
    "        for anc_cls in cls.ancestors():\n",
    "            ancestors_str.add(anc_cls.iri)\n",
    "        return ancestors_str\n",
    "\n",
    "    def getAncestorsNames(self,cls):\n",
    "        ancestors_str = set()\n",
    "        for anc_cls in cls.ancestors():\n",
    "            ancestors_str.add(anc_cls.name)\n",
    "        return ancestors_str\n",
    "\n",
    "    def getAncestors(self,cls):\n",
    "        ancestors_str = set()\n",
    "        for anc_cls in cls.ancestors():\n",
    "            ancestors_str.add(anc_cls)\n",
    "        return ancestors_str\n",
    "\n",
    "    def getDescendantURIs(self,cls):\n",
    "        descendants_str = set()\n",
    "        for desc_cls in cls.descendants():\n",
    "            descendants_str.add(desc_cls.iri)\n",
    "        return descendants_str\n",
    "\n",
    "    def getDescendantNames(self,cls):\n",
    "        descendants_str = set()\n",
    "        for desc_cls in cls.descendants():\n",
    "            descendants_str.add(desc_cls.name)\n",
    "        return descendants_str\n",
    "\n",
    "    def getDescendants(self,cls):\n",
    "        descendants_str = set()\n",
    "        for desc_cls in cls.descendants():\n",
    "            descendants_str.add(desc_cls)\n",
    "        return descendants_str\n",
    "\n",
    "    def getDescendantNamesForClassName(self, cls_name):\n",
    "        cls = self.getClassByName(cls_name)\n",
    "        descendants_str = set()\n",
    "        for desc_cls in cls.descendants():\n",
    "            descendants_str.add(desc_cls.name)\n",
    "        return descendants_str\n",
    "\n",
    "    def isSubClassOf(self, sub_cls1, sup_cls2):\n",
    "        if sup_cls2 in sub_cls1.ancestors():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def isSuperClassOf(self, sup_cls1, sub_cls2):\n",
    "        if sup_cls1 in sub_cls2.ancestors():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def getDomainURIs(self, prop):\n",
    "        domain_uris = set()\n",
    "        for cls in prop.domain:\n",
    "            try:\n",
    "                domain_uris.add(cls.iri)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "        return domain_uris\n",
    "\n",
    "    def getDatatypeRangeNames(self, prop):\n",
    "        range_uris = set()\n",
    "        for cls in prop.range:\n",
    "            range_uris.add(cls.name)  #datatypes are returned without uri\n",
    "        return range_uris\n",
    "\n",
    "    #Only for object properties\n",
    "    def getRangeURIs(self, prop):\n",
    "        range_uris = set()\n",
    "        for cls in prop.range:\n",
    "            try:\n",
    "                range_uris.add(cls.iri)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "        return range_uris\n",
    "\n",
    "    def getInverses(self, prop):\n",
    "        inv_uris = set()\n",
    "        for p in prop.inverse:\n",
    "            inv_uris.add(p.iri)\n",
    "        return inv_uris\n",
    "\n",
    "    def getClasses(self):\n",
    "        return self.getOntology().classes()\n",
    "\n",
    "    def getDataProperties(self):\n",
    "        return self.getOntology().data_properties()\n",
    "\n",
    "    def getObjectProperties(self):\n",
    "        return self.getOntology().object_properties()\n",
    "\n",
    "    def getIndividuals(self):\n",
    "        return self.getOntology().individuals()\n",
    "\n",
    "    def getGraph(self):\n",
    "        return self.graph\n",
    "\n",
    "    def queryGraph(self, query):\n",
    "        results = self.graph.query(query)\n",
    "        return list(results)\n",
    "\n",
    "\n",
    "    def getQueryForAnnotations(self, ann_prop_uri):\n",
    "        return \"\"\"SELECT DISTINCT ?s ?o WHERE {{\n",
    "        {{\n",
    "        ?s <{ann_prop}> ?o .\n",
    "        }}\n",
    "        UNION\n",
    "        {{\n",
    "        ?s <{ann_prop}> ?i .\n",
    "        ?i <http://www.w3.org/2000/01/rdf-schema#label> ?o .\n",
    "        }}\n",
    "        }}\"\"\".format(ann_prop=ann_prop_uri)\n",
    "\n",
    "\n",
    "    def indexAnnotations(self):\n",
    "        annotation_uris = AnnotationURIs()\n",
    "        self.entityToSynonyms = {}\n",
    "        self.allEntityAnnotations = {}\n",
    "        self.preferredLabels = {}\n",
    "        self.populateAnnotationDicts(annotation_uris.getAnnotationURIsForSymnonyms(), self.entityToSynonyms)\n",
    "        self.populateAnnotationDicts(annotation_uris.getAnnotationURIsForLexicalAnnotations(), self.allEntityAnnotations)\n",
    "        self.populateAnnotationDicts(annotation_uris.getAnnotationURIsForPreferredLabels(), self.preferredLabels)\n",
    "\n",
    "    def populateAnnotationDicts(self, annotation_uris, dictionary):\n",
    "        for ann_prop_uri in annotation_uris:\n",
    "            results = self.queryGraph(self.getQueryForAnnotations(ann_prop_uri))\n",
    "            for row in results:\n",
    "                try:\n",
    "                    if row[1].language==\"en\" or row[1].language==None:\n",
    "                        if not str(row[0]) in dictionary:\n",
    "                            dictionary[str(row[0])]=set()\n",
    "                        dictionary[str(row[0])].add(row[1].value)\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "        return None\n",
    "\n",
    "    def getSynonymsNames(self, entity):\n",
    "        if entity.iri not in self.entityToSynonyms: \n",
    "            return {}\n",
    "        return self.entityToSynonyms[entity.iri]\n",
    "\n",
    "    def getAnnotationNames(self, entity):\n",
    "        if entity.iri not in self.allEntityAnnotations: \n",
    "            return {}\n",
    "        return self.allEntityAnnotations[entity.iri]\n",
    "\n",
    "    def getPrefferedLabels(self, entity):\n",
    "        if entity.iri not in self.preferredLabels: \n",
    "            return {}\n",
    "        return self.preferredLabels[entity.iri]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:38:31.355461Z",
     "iopub.status.busy": "2024-11-12T11:38:31.354781Z",
     "iopub.status.idle": "2024-11-12T11:40:58.840825Z",
     "shell.execute_reply": "2024-11-12T11:40:58.839697Z",
     "shell.execute_reply.started": "2024-11-12T11:38:31.355414Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: There are 131185 triples in the ontology\n",
      "* Owlready2 * Creating new ontology ordo <rai-bioml-2024/omim-ordo/ordo.owl#>.\n",
      "* Owlready2 * ADD TRIPLE rai-bioml-2024/omim-ordo/ordo.owl http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://www.w3.org/2002/07/owl#Ontology\n",
      "* Owlready2 *     ...loading ontology ordo from rai-bioml-2024/omim-ordo/ordo.owl...\n",
      "* Owlready2 *     ...41 properties found: BFO_0000050, Orphanet_317343, Orphanet_317344, Orphanet_317345, Orphanet_317346, Orphanet_317348, Orphanet_317349, Orphanet_327767, Orphanet_410295, Orphanet_410296, Orphanet_465410, Orphanet_C016, Orphanet_C017, Orphanet_C020, Orphanet_C022, Orphanet_C025, Orphanet_C026, Orphanet_C027, Orphanet_C024, Orphanet_C028, Orphanet_C029, Orphanet_C030, Orphanet_C032, Orphanet_C040, label, versionInfo, use_in_alignment, alternative_term, ECO_0000205, ECO_0000218, creator, created, license, modified, definition, definition_citation, reason_for_obsolescence, symbol, notation, permits, requires\n",
      "INFO: There are 673158 triples in the ontology\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Reseting property ann.use_in_alignment: new triples are now available.\n"
     ]
    }
   ],
   "source": [
    "# check if the enviroment is kaggle or local\n",
    "DATASET_PATH = Path('/kaggle/input/')\n",
    "if not DATASET_PATH.exists():\n",
    "    DATASET_PATH = Path('.')\n",
    "DATASET_PATH /= 'rai-bioml-2024'\n",
    "\n",
    "src_onto_path = DATASET_PATH / 'omim-ordo/omim.owl'\n",
    "tgt_onto_path = DATASET_PATH / 'omim-ordo/ordo.owl'\n",
    "\n",
    "onto_src = OntologyAccess(src_onto_path, annotate_on_init=False)\n",
    "onto_src.loadOntology()\n",
    "onto_src.indexAnnotations()\n",
    "\n",
    "onto_tgt = OntologyAccess(tgt_onto_path, annotate_on_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:40:58.843195Z",
     "iopub.status.busy": "2024-11-12T11:40:58.842863Z",
     "iopub.status.idle": "2024-11-12T11:40:59.309822Z",
     "shell.execute_reply": "2024-11-12T11:40:59.308748Z",
     "shell.execute_reply.started": "2024-11-12T11:40:58.843155Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[entry.100050, entry.100070, phenotypicSeries.PS100070, entry.100100, entry.100200, entry.100300, phenotypicSeries.PS100300, entry.100600, entry.100700, entry.100800, entry.100820, entry.101000, entry.101120, entry.101200, entry.101400, entry.101600, entry.101800, phenotypicSeries.PS101800, entry.101805, entry.101840, entry.101850, entry.101900, entry.102000, entry.102100, entry.102150] <class 'owlready2.entity.ThingClass'>\n"
     ]
    }
   ],
   "source": [
    "onto_classes = [x for x in onto_src.getClasses()]\n",
    "print(onto_classes[:25], type(onto_classes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:40:59.311481Z",
     "iopub.status.busy": "2024-11-12T11:40:59.311117Z",
     "iopub.status.idle": "2024-11-12T11:40:59.617424Z",
     "shell.execute_reply": "2024-11-12T11:40:59.616429Z",
     "shell.execute_reply.started": "2024-11-12T11:40:59.311443Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frontotemporal dementia and/or amyotrophic lateral sclerosis 1': [{'frontotemporal dementia and/or amyotrophic lateral sclerosis 1'},\n",
       "  {},\n",
       "  {'Frontotemporal dementia and/or amyotrophic lateral sclerosis'},\n",
       "  {'Amyotrophic lateral sclerosis'}],\n",
       " 'albinism, oculocutaneous,  iia 6': [{'albinism, oculocutaneous,  iia 6'},\n",
       "  {'Skin/hair/eye pigmentation, variation in'},\n",
       "  {},\n",
       "  {'Oculocutaneous albinism'}],\n",
       " 'episodic kinesigenic dyskinesia 1': [{'Dystonia'},\n",
       "  {},\n",
       "  {'Episodic kinesigenic dyskinesia'},\n",
       "  {'episodic kinesigenic dyskinesia 1'}],\n",
       " 'coffin-siris syndrome 1': [{'Intellectual developmental disorder, autosomal dominant'},\n",
       "  {},\n",
       "  {'coffin-siris syndrome 1'},\n",
       "  {'Coffin-Siris syndrome'}],\n",
       " 'bethlem myopathy 1': [{'Muscular dystrophy, limb-girdle, autosomal dominant'},\n",
       "  {},\n",
       "  {'bethlem myopathy 1'},\n",
       "  {'Bethlem myopathy'}]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ancestors = {x:values for x in onto_src.getClasses() if len(values:=onto_src.getAncestors(x))>3}\n",
    "ancestors_labels = {'\\n'.join(onto_src.getPrefferedLabels(x)):[\n",
    "    onto_src.getPrefferedLabels(y) for y in values] \n",
    "                    for x, values in ancestors.items()}\n",
    "dict(list(ancestors_labels.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:40:59.620672Z",
     "iopub.status.busy": "2024-11-12T11:40:59.620133Z",
     "iopub.status.idle": "2024-11-12T11:40:59.842434Z",
     "shell.execute_reply": "2024-11-12T11:40:59.841411Z",
     "shell.execute_reply.started": "2024-11-12T11:40:59.620636Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aortic aneurysm, familial abdominal': [{'aortic aneurysm, familial abdominal, 2'},\n",
       "  {'aortic aneurysm, familial abdominal, 3'},\n",
       "  {'aortic aneurysm, familial abdominal, 1'},\n",
       "  {'aortic aneurysm, familial abdominal, 4'},\n",
       "  {'Aortic aneurysm, familial abdominal'}],\n",
       " 'Adams-Oliver syndrome': [{'adams-oliver syndrome 5'},\n",
       "  {'Adams-Oliver syndrome'},\n",
       "  {'adams-oliver syndrome 4'},\n",
       "  {'adams-oliver syndrome 3'},\n",
       "  {'adams-oliver syndrome 1'},\n",
       "  {'adams-oliver syndrome 2'},\n",
       "  {'adams-oliver syndrome 6'}],\n",
       " 'Acrodysostosis': [{'acrodysostosis 1 with or without hormone resistance'},\n",
       "  {'Acrodysostosis'},\n",
       "  {'acrodysostosis 2 with or without hormone resistance'}],\n",
       " 'Pituitary adenoma': [{'pituitary adenoma 2, growth hormone-secreting'},\n",
       "  {'pituitary adenoma 3, multiple types'},\n",
       "  {'pituitary adenoma 1, multiple types'},\n",
       "  {'pituitary adenoma 5, multiple types'},\n",
       "  {'pituitary adenoma 4, acth-secreting'},\n",
       "  {'Pituitary adenoma'}],\n",
       " 'Restless legs syndrome': [{'restless legs syndrome, susceptibility to, 5'},\n",
       "  {'restless legs syndrome, susceptibility to, 7'},\n",
       "  {'restless legs syndrome, susceptibility to, 1'},\n",
       "  {'restless legs syndrome, susceptibility to, 4'},\n",
       "  {'restless legs syndrome, susceptibility to, 3'},\n",
       "  {'restless legs syndrome, susceptibility to, 6'},\n",
       "  {'Restless legs syndrome'},\n",
       "  {'restless legs syndrome, susceptibility to, 8'},\n",
       "  {'restless legs syndrome, susceptibility to, 2'}]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descendants = {x: values for x in onto_src.getClasses() if len(values:=onto_src.getDescendants(x)) > 2}\n",
    "descendant_names = {'\\n'.join(onto_src.getPrefferedLabels(x)): \n",
    "            [onto_src.getPrefferedLabels(y) for y in values] for x, values in descendants.items()}\n",
    "dict(list(descendant_names.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:40:59.844247Z",
     "iopub.status.busy": "2024-11-12T11:40:59.843896Z",
     "iopub.status.idle": "2024-11-12T11:40:59.913590Z",
     "shell.execute_reply": "2024-11-12T11:40:59.912425Z",
     "shell.execute_reply.started": "2024-11-12T11:40:59.844209Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{entry.100070: {'AAA1'},\n",
       " entry.100100: {'PBS'},\n",
       " entry.100300: {'AOS1'},\n",
       " entry.100800: {'ACH'},\n",
       " entry.101000: {'NF2'},\n",
       " entry.101400: {'SCS'},\n",
       " entry.101800: {'ACRDYS1'},\n",
       " entry.101850: {'PPKP3'},\n",
       " entry.101900: {'AKV'},\n",
       " entry.102200: {'PITA1'}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms = {x:values for x in onto_src.getClasses() if len(values:=onto_src.getSynonymsNames(x))>0}\n",
    "dict(list(synonyms.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:40:59.915277Z",
     "iopub.status.busy": "2024-11-12T11:40:59.914906Z",
     "iopub.status.idle": "2024-11-12T11:40:59.986941Z",
     "shell.execute_reply": "2024-11-12T11:40:59.985956Z",
     "shell.execute_reply.started": "2024-11-12T11:40:59.915218Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{entry.100070: {'AAA1', 'aortic aneurysm, familial abdominal, 1'},\n",
       " entry.100100: {'PBS', 'prune belly syndrome'},\n",
       " entry.100300: {'AOS1', 'adams-oliver syndrome 1'},\n",
       " entry.100800: {'ACH', 'achondroplasia'},\n",
       " entry.101000: {'NF2', 'neurofibromatosis,  iia 2'},\n",
       " entry.101400: {'SCS', 'saethre-chotzen syndrome'},\n",
       " entry.101800: {'ACRDYS1',\n",
       "  'acrodysostosis 1 with or without hormone resistance'},\n",
       " entry.101850: {'PPKP3', 'palmoplantar keratoderma, punctate  iia 3'},\n",
       " entry.101900: {'AKV', 'acrokeratosis verruciformis'},\n",
       " entry.102200: {'PITA1', 'pituitary adenoma 1, multiple types'}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_labels = {x:values for x in onto_src.getClasses() if len(values:=onto_src.getAnnotationNames(x))>1}\n",
    "dict(list(annotation_labels.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:40:59.988594Z",
     "iopub.status.busy": "2024-11-12T11:40:59.988251Z",
     "iopub.status.idle": "2024-11-12T11:41:02.233715Z",
     "shell.execute_reply": "2024-11-12T11:41:02.232737Z",
     "shell.execute_reply.started": "2024-11-12T11:40:59.988559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ORDO.Orphanet_100006: {'ABeta amyloidosis, Dutch type',\n",
       "  'ABetaE22Q amyloidosis',\n",
       "  'HCHWA, Dutch type',\n",
       "  'HCHWA-D',\n",
       "  'Hereditary cerebral hemorrhage with amyloidosis, Dutch type'},\n",
       " ORDO.Orphanet_100008: {'ACys amyloidosis',\n",
       "  'CST3-related amyloidosis',\n",
       "  'Cystatin amyloidosis',\n",
       "  'HCHWA, Icelandic type',\n",
       "  'Hereditary cerebral hemorrhage with amyloidosis, Icelandic type',\n",
       "  'Hereditary cystatin C amyloid angiopathy'},\n",
       " ORDO.Orphanet_100025: {'Alpha-HCD',\n",
       "  'Alpha-heavy chain disease',\n",
       "  'IPSID',\n",
       "  'Immunoproliferative small intestinal disease',\n",
       "  'Mediterranean lymphoma'},\n",
       " ORDO.Orphanet_100026: {'Franklin disease',\n",
       "  'Gamma-HCD',\n",
       "  'Gamma-heavy chain disease'},\n",
       " ORDO.Orphanet_100050: {'HAE 1',\n",
       "  'HAE-I',\n",
       "  'Hereditary angioedema type 1',\n",
       "  'Hereditary angioneurotic edema type 1'},\n",
       " ORDO.Orphanet_528623: {'HAE with C1 inhibitor deficiency',\n",
       "  'HAE with C1Inh deficiency',\n",
       "  'Hereditary angioedema with C1Inh deficiency',\n",
       "  'Hereditary angioneurotic edema with C1 inhibitor deficiency',\n",
       "  'Hereditary angioneurotic edema with C1Inh deficiency'},\n",
       " ORDO.Orphanet_100051: {'HAE 2',\n",
       "  'HAE-II',\n",
       "  'Hereditary angioedema type 2',\n",
       "  'Hereditary angioneurotic edema type 2'},\n",
       " ORDO.Orphanet_100054: {'F12-related HAE with normal C1 inhibitor',\n",
       "  'F12-related hereditary angioedema with normal C1Inh',\n",
       "  'HAE 3',\n",
       "  'HAE-III',\n",
       "  'Hereditary angioedema type 3',\n",
       "  'Hereditary angioneurotic edema type 3',\n",
       "  'Inherited estrogen-associated angioedema',\n",
       "  'Inherited estrogen-associated angioneurotic edema',\n",
       "  'Inherited estrogen-dependent angioedema',\n",
       "  'Inherited estrogen-dependent angioneurotic edema'},\n",
       " ORDO.Orphanet_528647: {'HAE with normal C1 inhibitor',\n",
       "  'HAE with normal C1Inh',\n",
       "  'Hereditary angioedema with normal C1 inhibitor',\n",
       "  'Hereditary angioedema with normal C1Inh',\n",
       "  'Hereditary angioneurotic edema with normal C1 inhibitor',\n",
       "  'Hereditary angioneurotic edema with normal C1Inh'},\n",
       " ORDO.Orphanet_100055: {'AAE 2',\n",
       "  'AAE II',\n",
       "  'Acquired angioedema type 2',\n",
       "  'Acquired angioneurotic edema type 2'}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_labels = {x:values for x in onto_tgt.getClasses() if len(values:=onto_tgt.getAnnotationNames(x))>2}\n",
    "dict(list(annotation_labels.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:41:02.235508Z",
     "iopub.status.busy": "2024-11-12T11:41:02.235088Z",
     "iopub.status.idle": "2024-11-12T11:41:02.247950Z",
     "shell.execute_reply": "2024-11-12T11:41:02.246953Z",
     "shell.execute_reply.started": "2024-11-12T11:41:02.235460Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class OntologyEntryAttr:\n",
    "    ## TODO: Add more attributes: direct children and parents\n",
    "    def __init__(self, class_uri, onto: OntologyAccess, class_id=None):\n",
    "        assert class_uri is not None or class_id is not None\n",
    "        if class_uri is not None:\n",
    "            self.class_id = onto.getClassByURI(class_uri)\n",
    "        else:\n",
    "            self.class_id = class_id\n",
    "        assert self.class_id is not None\n",
    "        self.annotation = {'class': self.class_id}\n",
    "        self.onto:OntologyAccess = onto\n",
    "        self.annotateEntry(onto)\n",
    "\n",
    "    def annotateEntry(self, onto: OntologyAccess):\n",
    "        logging.debug(f\"Annotating {self.class_id}\")\n",
    "        self.annotation['children'] = onto.getDescendants(self.class_id)\n",
    "        self.annotation['parents'] = onto.getAncestors(self.class_id)\n",
    "        self.annotation['synonyms'] = onto.getSynonymsNames(self.class_id)\n",
    "        self.annotation['names'] = onto.getAnnotationNames(self.class_id)\n",
    "\n",
    "    def getAllEntetyNames(self):\n",
    "        return self.annotation['names']\n",
    "\n",
    "    def getSynonyms(self):\n",
    "        return self.annotation['synonyms']\n",
    "    \n",
    "    def getChildren(self, skip_itself=True):\n",
    "        result = self.annotation['children']\n",
    "        if skip_itself:\n",
    "            result = result.difference({self.class_id})\n",
    "        return result\n",
    "\n",
    "    def getParents(self, skip_itself=True):\n",
    "        result = self.annotation['parents']\n",
    "        if skip_itself:\n",
    "            result = result.difference({self.class_id})\n",
    "        return result\n",
    "\n",
    "    def getParentsPreferredNames(self, skip_itself=True):\n",
    "        labels = []\n",
    "        for parent in self.getParents(skip_itself=skip_itself):\n",
    "            preffered = self.onto.getPrefferedLabels(parent)\n",
    "            if preffered:\n",
    "                labels.append(preffered)\n",
    "            else:\n",
    "                labels.append({parent})\n",
    "        return labels\n",
    "\n",
    "    def getChildredPreferredNames(self, skip_itself=True):\n",
    "        return [preffered if (preffered := self.onto.getPrefferedLabels(child)) else {child}\n",
    "                for child in self.getChildren(skip_itself=skip_itself)]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.annotation)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:41:02.249571Z",
     "iopub.status.busy": "2024-11-12T11:41:02.249292Z",
     "iopub.status.idle": "2024-11-12T11:41:02.333240Z",
     "shell.execute_reply": "2024-11-12T11:41:02.332109Z",
     "shell.execute_reply.started": "2024-11-12T11:41:02.249540Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotating entry.609560\n",
      "Annotating ORDO.Orphanet_254875\n"
     ]
    }
   ],
   "source": [
    "source_entity_uri = 'http://omim.org/entry/609560' #'http://omim.org/entry/100070'\n",
    "target_entity_uri = 'http://www.orpha.net/ORDO/Orphanet_254875' #'http://omim.org/entry/101900'\n",
    "source_entry = OntologyEntryAttr(source_entity_uri, onto_src)\n",
    "target_entity = OntologyEntryAttr(target_entity_uri, onto_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:41:02.339095Z",
     "iopub.status.busy": "2024-11-12T11:41:02.338380Z",
     "iopub.status.idle": "2024-11-12T11:41:02.343565Z",
     "shell.execute_reply": "2024-11-12T11:41:02.342619Z",
     "shell.execute_reply.started": "2024-11-12T11:41:02.339059Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': entry.609560, 'synonyms': {'MTDPS2'}, 'names': {'mitochondrial DNA depletion syndrome 2 (myopathic type)', 'MTDPS2'}, 'children': {entry.609560}, 'parents': {phenotypicSeries.PS603041, entry.609560, owl.Thing}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': ORDO.Orphanet_254875, 'synonyms': {'mtDNA depletion syndrome, myopathic form'}, 'names': {'mtDNA depletion syndrome, myopathic form', 'Mitochondrial DNA depletion syndrome, myopathic form'}, 'children': {ORDO.Orphanet_254875}, 'parents': {ORDO.Orphanet_377788, owl.Thing, ORDO.Orphanet_254875, ORDO.Orphanet_C001}}\n"
     ]
    }
   ],
   "source": [
    "display(source_entry)\n",
    "print(target_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:41:02.344990Z",
     "iopub.status.busy": "2024-11-12T11:41:02.344695Z",
     "iopub.status.idle": "2024-11-12T11:41:02.356508Z",
     "shell.execute_reply": "2024-11-12T11:41:02.355633Z",
     "shell.execute_reply.started": "2024-11-12T11:41:02.344959Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Source entity names: {'mitochondrial DNA depletion syndrome 2 (myopathic type)', 'MTDPS2'}\n",
      " Source entity synonyms: {'MTDPS2'}\n",
      " Source entity children names: [{'mitochondrial DNA depletion syndrome 2 (myopathic type)'}]\n",
      " Source entity children names: []\n",
      " Source entity parents names: [{'Mitochondrial DNA depletion syndrome'}, {owl.Thing}]\n",
      " Source entity parents: {phenotypicSeries.PS603041, owl.Thing}\n"
     ]
    }
   ],
   "source": [
    "print(f\" Source entity names: {source_entry.getAllEntetyNames()}\")\n",
    "print(f\" Source entity synonyms: {source_entry.getSynonyms()}\")\n",
    "print(f\" Source entity children names: {source_entry.getChildredPreferredNames(skip_itself=False)}\")\n",
    "print(f\" Source entity children names: {source_entry.getChildredPreferredNames(skip_itself=True)}\")\n",
    "print(f\" Source entity parents names: {source_entry.getParentsPreferredNames()}\")\n",
    "print(f\" Source entity parents: {source_entry.getParents()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:41:02.357933Z",
     "iopub.status.busy": "2024-11-12T11:41:02.357646Z",
     "iopub.status.idle": "2024-11-12T11:41:02.371606Z",
     "shell.execute_reply": "2024-11-12T11:41:02.370781Z",
     "shell.execute_reply.started": "2024-11-12T11:41:02.357901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def composePrompt(source_entry:OntologyEntryAttr, target_entry:OntologyEntryAttr):\n",
    "    return f\"\"\"\n",
    "**Task Description:**\n",
    "Given two sets of concepts with their names, parent relationships, and child relationships, determine if these concepts are identical. Evaluate based on the provided names and hierarchical structures.\n",
    "**Template for Alignment:**\n",
    "\n",
    "1. **Source Concept:**\n",
    "**Names:** [List of source concept names]\n",
    "**Parent Concepts:** [List of source concept's parent names]\n",
    "**Child Concepts:** [List of source concept's child names]\n",
    "2. **Target Concept:**\n",
    "**Names:** [List of target concept names]\n",
    "**Parent Concepts:** [List of target concept's parent names]\n",
    "**Child Concepts:** [List of target concept's child names]\n",
    "**Determine Concept Equivalence:**\n",
    "Analyze whether the source and target concepts are equivalent based on names, parent concepts, and child concepts. Provide your conclusion (\"Yes\" for identical, \"No\" for different).\n",
    "\n",
    "**Example Prompts (Few-Shot Examples):**\n",
    "\n",
    "1. **Example 1:**\n",
    "Source Concept Names: [e.g., \"Entity_A\"]\n",
    "Parent of Source Concept: [e.g., \"Parent_A\"]\n",
    "Child of Source Concept: [e.g., \"Child_A\"]\n",
    "Target Concept Names: [e.g., \"Entity_B\"]\n",
    "Parent of Target Concept: [e.g., \"Parent_B\"]\n",
    "Child of Target Concept: [e.g., \"Child_B\"]\n",
    "\n",
    "**Conclusion:** No\n",
    "\n",
    "2. **Example 2:**\n",
    "Source Concept Names: [e.g., \"Entity_X\"]\n",
    "Parent of Source Concept: [e.g., \"Parent_X\"]\n",
    "Child of Source Concept: [e.g., \"Child_X\"]\n",
    "Target Concept Names: [e.g., \"Entity_X\"]\n",
    "Parent of Target Concept: [e.g., \"Parent_X\"]\n",
    "Child of Target Concept: [e.g., \"Child_X\"]\n",
    "**Conclusion:** Yes\n",
    "**Now Answer:**\n",
    "\n",
    "Source Concept Names: {source_entry.getAllEntetyNames()}\n",
    "Parent of Source Concept: {source_entry.getParentsPreferredNames()}\n",
    "Child of Source Concept: {source_entry.getChildredPreferredNames()}\n",
    "Target Concept Names: {target_entry.getAllEntetyNames()}\n",
    "Parent of Target Concept: {target_entry.getParentsPreferredNames()}\n",
    "Child of Target Concept: {target_entry.getChildredPreferredNames()}\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:41:02.373280Z",
     "iopub.status.busy": "2024-11-12T11:41:02.372786Z",
     "iopub.status.idle": "2024-11-12T11:41:02.456155Z",
     "shell.execute_reply": "2024-11-12T11:41:02.455177Z",
     "shell.execute_reply.started": "2024-11-12T11:41:02.373110Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotating entry.609560\n",
      "Annotating ORDO.Orphanet_254875\n",
      "\n",
      "**Task Description:**\n",
      "Given two sets of concepts with their names, parent relationships, and child relationships, determine if these concepts are identical. Evaluate based on the provided names and hierarchical structures.\n",
      "**Template for Alignment:**\n",
      "\n",
      "1. **Source Concept:**\n",
      "**Names:** [List of source concept names]\n",
      "**Parent Concepts:** [List of source concept's parent names]\n",
      "**Child Concepts:** [List of source concept's child names]\n",
      "2. **Target Concept:**\n",
      "**Names:** [List of target concept names]\n",
      "**Parent Concepts:** [List of target concept's parent names]\n",
      "**Child Concepts:** [List of target concept's child names]\n",
      "**Determine Concept Equivalence:**\n",
      "Analyze whether the source and target concepts are equivalent based on names, parent concepts, and child concepts. Provide your conclusion (\"Yes\" for identical, \"No\" for different).\n",
      "\n",
      "**Example Prompts (Few-Shot Examples):**\n",
      "\n",
      "1. **Example 1:**\n",
      "Source Concept Names: [e.g., \"Entity_A\"]\n",
      "Parent of Source Concept: [e.g., \"Parent_A\"]\n",
      "Child of Source Concept: [e.g., \"Child_A\"]\n",
      "Target Concept Names: [e.g., \"Entity_B\"]\n",
      "Parent of Target Concept: [e.g., \"Parent_B\"]\n",
      "Child of Target Concept: [e.g., \"Child_B\"]\n",
      "\n",
      "**Conclusion:** No\n",
      "\n",
      "2. **Example 2:**\n",
      "Source Concept Names: [e.g., \"Entity_X\"]\n",
      "Parent of Source Concept: [e.g., \"Parent_X\"]\n",
      "Child of Source Concept: [e.g., \"Child_X\"]\n",
      "Target Concept Names: [e.g., \"Entity_X\"]\n",
      "Parent of Target Concept: [e.g., \"Parent_X\"]\n",
      "Child of Target Concept: [e.g., \"Child_X\"]\n",
      "**Conclusion:** Yes\n",
      "**Now Answer:**\n",
      "\n",
      "Source Concept Names: {'mitochondrial DNA depletion syndrome 2 (myopathic type)', 'MTDPS2'}\n",
      "Parent of Source Concept: [{'Mitochondrial DNA depletion syndrome'}, {'mitochondrial DNA depletion syndrome 2 (myopathic type)'}, owl.Thing]\n",
      "Child of Source Concept: [{'mitochondrial DNA depletion syndrome 2 (myopathic type)'}]\n",
      "Target Concept Names: {'mtDNA depletion syndrome, myopathic form', 'Mitochondrial DNA depletion syndrome, myopathic form'}\n",
      "Parent of Target Concept: [{'disease'}, owl.Thing, {'Mitochondrial DNA depletion syndrome, myopathic form'}, {'clinical entity'}]\n",
      "Child of Target Concept: [{'Mitochondrial DNA depletion syndrome, myopathic form'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_entity_uri = 'http://omim.org/entry/609560' #'http://omim.org/entry/100070'\n",
    "target_entity_uri = 'http://www.orpha.net/ORDO/Orphanet_254875' #'http://omim.org/entry/101900'\n",
    "source_entity = OntologyEntryAttr(source_entity_uri, onto_src)\n",
    "target_entity = OntologyEntryAttr(target_entity_uri, onto_tgt)\n",
    "demo_prompt = composePrompt(source_entity, target_entity)\n",
    "print(demo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:41:02.457717Z",
     "iopub.status.busy": "2024-11-12T11:41:02.457424Z",
     "iopub.status.idle": "2024-11-12T11:41:11.276981Z",
     "shell.execute_reply": "2024-11-12T11:41:11.275992Z",
     "shell.execute_reply.started": "2024-11-12T11:41:02.457685Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Conclusion:** No\n",
      "\n",
      "The source concept and target concept are not identical. Although they both refer to the same condition, Mitochondrial DNA depletion syndrome, myopathic form, they have different names and their parent concepts are not the same. The source concept has only one parent, while the target concept has multiple parents. Additionally, the child concepts are different, with the source concept having only 'mitochondrial DNA depletion syndrome 2 (myopathic type)' as a child, while the target concept has ORDO.Orphanet_254875 as a child.\n"
     ]
    }
   ],
   "source": [
    "response = mistral.ask_question(demo_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:42:36.538319Z",
     "iopub.status.busy": "2024-11-12T11:42:36.537380Z",
     "iopub.status.idle": "2024-11-12T11:42:36.767588Z",
     "shell.execute_reply": "2024-11-12T11:42:36.766696Z",
     "shell.execute_reply.started": "2024-11-12T11:42:36.538274Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_candidates_path = DATASET_PATH / \"omim-ordo/refs_equiv/test.cands.tsv\"\n",
    "test_candidates = pd.read_csv(test_candidates_path, sep='\\t')\n",
    "test_candidates['TgtCandidates'] = test_candidates['TgtCandidates'].str.strip(\"('\").str.strip(\"')\").str.split(\"', '\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:49:37.729933Z",
     "iopub.status.busy": "2024-11-12T11:49:37.729500Z",
     "iopub.status.idle": "2024-11-12T11:49:37.748089Z",
     "shell.execute_reply": "2024-11-12T11:49:37.747012Z",
     "shell.execute_reply.started": "2024-11-12T11:49:37.729892Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcEntity</th>\n",
       "      <th>TgtEntity</th>\n",
       "      <th>TgtCandidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_98464</td>\n",
       "      <td>[http://www.orpha.net/ORDO/Orphanet_93406, htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://omim.org/entry/615075</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_404473</td>\n",
       "      <td>[http://www.orpha.net/ORDO/Orphanet_157791, ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://omim.org/entry/613724</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_163684</td>\n",
       "      <td>[http://www.orpha.net/ORDO/Orphanet_639, http:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://omim.org/entry/602066</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_31709</td>\n",
       "      <td>[http://www.orpha.net/ORDO/Orphanet_99141, htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://omim.org/entry/167730</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_2399</td>\n",
       "      <td>[http://www.orpha.net/ORDO/Orphanet_1475, http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SrcEntity  \\\n",
       "0  http://www.omim.org/phenotypicSeries/PS309510   \n",
       "1                   http://omim.org/entry/615075   \n",
       "2                   http://omim.org/entry/613724   \n",
       "3                   http://omim.org/entry/602066   \n",
       "4                   http://omim.org/entry/167730   \n",
       "\n",
       "                                   TgtEntity  \\\n",
       "0   http://www.orpha.net/ORDO/Orphanet_98464   \n",
       "1  http://www.orpha.net/ORDO/Orphanet_404473   \n",
       "2  http://www.orpha.net/ORDO/Orphanet_163684   \n",
       "3   http://www.orpha.net/ORDO/Orphanet_31709   \n",
       "4    http://www.orpha.net/ORDO/Orphanet_2399   \n",
       "\n",
       "                                       TgtCandidates  \n",
       "0  [http://www.orpha.net/ORDO/Orphanet_93406, htt...  \n",
       "1  [http://www.orpha.net/ORDO/Orphanet_157791, ht...  \n",
       "2  [http://www.orpha.net/ORDO/Orphanet_639, http:...  \n",
       "3  [http://www.orpha.net/ORDO/Orphanet_99141, htt...  \n",
       "4  [http://www.orpha.net/ORDO/Orphanet_1475, http...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_onto_path = DATASET_PATH / 'omim-ordo/omim.owl'\n",
    "# tgt_onto_path = DATASET_PATH / 'omim-ordo/ordo.owl'\n",
    "\n",
    "# onto_src = OntologyAccess(src_onto_path, annotate_on_init=True)\n",
    "# onto_tgt = OntologyAccess(tgt_onto_path, annotate_on_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_prompt(src_entety:OntologyEntryAttr, tgt_entety:OntologyEntryAttr):\n",
    "    return f\"\"\"\n",
    "    **Task Description:**\n",
    "    Given two entities from different ontologies with their names, parent relationships, and child relationships, determine if these concepts are the same:\n",
    "\n",
    "    1. **Source Entity:**\n",
    "    **All Entity names:** {src_entety.getAllEntetyNames()}\n",
    "    **Parent Entity Namings:** {src_entety.getParentsPreferredNames()}\n",
    "    **Child Entity Namings:** {src_entety.getChildredPreferredNames()}\n",
    "\n",
    "    2. **Target Entity:**\n",
    "    **All Entity names:** {tgt_entety.getAllEntetyNames()}\n",
    "    **Parent Entity Namings:** {tgt_entety.getParentsPreferredNames()}\n",
    "    **Child Entity Namings:** {tgt_entety.getChildredPreferredNames()}\n",
    "\n",
    "    Write \"Yes\" if the entities refer to the same concepts, and \"No\" otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "def dummy_answer_extraction(response:str):\n",
    "    \"\"\"\n",
    "    Returns 'Yes', 'No' or None based on the response, \n",
    "    Decision is made based on the presence of positive or negative words in the response\n",
    "    \"\"\"\n",
    "    response = response.lower().strip()\n",
    "    positive_words = [\"yes\", \"yeah\", \"yep\", \"correct\", \"true\"]\n",
    "    negative_words = [\"no\", \"nah\", \"nope\", \"wrong\", \"false\"]\n",
    "    is_positive = any([word in response for word in positive_words])\n",
    "    is_negative = any([word in response for word in negative_words])\n",
    "    if is_positive and not is_negative:\n",
    "        return \"Yes\"\n",
    "    elif is_negative and not is_positive:\n",
    "        return \"No\"\n",
    "    elif not is_positive and not is_negative:\n",
    "        return None\n",
    "    response = response.split('\\n')\n",
    "    for line in response:\n",
    "        if \"yes\" in line:\n",
    "            return \"Yes\"\n",
    "        elif \"no\" in line:\n",
    "            return \"No\"\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcEntity</th>\n",
       "      <th>TgtCandidate</th>\n",
       "      <th>ModelAnswer</th>\n",
       "      <th>RealAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_93406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_3231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_293642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_90025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_163209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_225147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_466084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_183530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_85275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         SrcEntity  \\\n",
       "0    http://www.omim.org/phenotypicSeries/PS309510   \n",
       "1    http://www.omim.org/phenotypicSeries/PS309510   \n",
       "2    http://www.omim.org/phenotypicSeries/PS309510   \n",
       "3    http://www.omim.org/phenotypicSeries/PS309510   \n",
       "4    http://www.omim.org/phenotypicSeries/PS309510   \n",
       "..                                             ...   \n",
       "96   http://www.omim.org/phenotypicSeries/PS309510   \n",
       "97   http://www.omim.org/phenotypicSeries/PS309510   \n",
       "98   http://www.omim.org/phenotypicSeries/PS309510   \n",
       "99   http://www.omim.org/phenotypicSeries/PS309510   \n",
       "100  http://www.omim.org/phenotypicSeries/PS309510   \n",
       "\n",
       "                                  TgtCandidate ModelAnswer RealAnswer  \n",
       "0     http://www.orpha.net/ORDO/Orphanet_93406         NaN         No  \n",
       "1       http://www.orpha.net/ORDO/Orphanet_181         NaN         No  \n",
       "2      http://www.orpha.net/ORDO/Orphanet_3231         NaN         No  \n",
       "3    http://www.orpha.net/ORDO/Orphanet_293642         NaN         No  \n",
       "4     http://www.orpha.net/ORDO/Orphanet_90025         NaN         No  \n",
       "..                                         ...         ...        ...  \n",
       "96   http://www.orpha.net/ORDO/Orphanet_163209         NaN         No  \n",
       "97   http://www.orpha.net/ORDO/Orphanet_225147         NaN         No  \n",
       "98   http://www.orpha.net/ORDO/Orphanet_466084         NaN         No  \n",
       "99   http://www.orpha.net/ORDO/Orphanet_183530         NaN         No  \n",
       "100   http://www.orpha.net/ORDO/Orphanet_85275         NaN         No  \n",
       "\n",
       "[101 rows x 4 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case = test_candidates.iloc[0]\n",
    "\n",
    "test_case_results_df = pd.DataFrame(columns=['SrcEntity', 'TgtCandidate', 'ModelAnswer', 'RealAnswer'])\n",
    "test_case_results_df['TgtCandidate'] = test_case['TgtCandidates']\n",
    "test_case_results_df['SrcEntity'] = test_case['SrcEntity']\n",
    "test_case_results_df['RealAnswer'] = test_case_results_df['TgtCandidate'].apply(lambda x: \"Yes\" if x == test_case['TgtEntity'] else \"No\")\n",
    "test_case_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    **Task Description:**\n",
      "    Given two sets of concepts with their names, parent relationships, and child relationships, determine if these concepts are the same:\n",
      "\n",
      "    1. **Source Concept:**\n",
      "    **All its names:** {'Intellectual developmental disorder, X-linked syndromic'}\n",
      "    **Parent Concept Namings:** [{owl.Thing}]\n",
      "    **Child Concept Namings:** [{'intellectual developmental disorder, x-linked, syndromic 11'}, {'prieto X-linked mental retardation syndrome'}, {'basilicata-akhtar syndrome'}, {'mehmo syndrome'}, {'abidi X-linked mental retardation syndrome'}, {'corpus callosum, agenesis of, with impaired intellectual development, ocular coloboma, and micrognathia'}, {\"van esch-o'driscoll syndrome\"}, {'raynaud-claes syndrome'}, {'arts syndrome'}, {'intellectual developmental disorder, x-linked, syndromic, lubs  iia'}, {'intellectual developmental disorder, x-linked, syndromic 7'}, {'intellectual developmental disorder, x-linked, syndromic, siderius  iia'}, {'paganini-miozzo syndrome'}, {'partington syndrome'}, {'intellectual developmental disorder, x-linked, syndromic, snyder-robinson  iia'}, {'intellectual developmental disorder, x-linked, syndromic, christianson  iia'}, {'borjeson-forssman-lehmann syndrome'}, {'mental retardation, x-linked, syndromic, chudley-schwartz  iia'}, {'intellectual developmental disorder, x-linked, syndromic, stocco dos santos  iia'}, {'intellectual developmental disorder, x-linked, syndromic 34'}, {'wieacker-wolff syndrome'}, {'mental retardation, x-linked, syndromic 17'}, {'intellectual developmental disorder, x-linked, syndromic, lujan-fryns  iia'}, {'intellectual developmental disorder, x-linked, syndromic, snijders blok  iia'}, {'intellectual developmental disorder, x-linked, syndromic, 35'}, {'intellectual developmental disorder, x-linked, syndromic, hackmann-di donato  iia'}, {'mental retardation, x-linked, syndromic 12'}, {'intellectual developmental disorder, x-linked, syndromic 32'}, {'pettigrew syndrome'}, {'intellectual developmental disorder, x-linked, syndromic, hedera  iia'}, {'mental retardation, x-linked, syndromic 9'}, {'intellectual developmental disorder, x-linked, syndromic, turner  iia'}, {'intellectual developmental disorder, x-linked, syndromic, raymond  iia'}, {'intellectual developmental disorder, x-linked, syndromic 13'}, {'intellectual developmental disorder, x-linked, syndromic, houge  iia'}, {'intellectual developmental disorder, x-linked, syndromic, armfield  iia'}, {'intellectual developmental disorder, x-linked, syndromic, billuart  iia'}, {'intellectual developmental disorder, x-linked, syndromic, bain  iia'}, {'tonne-kalscheuer syndrome'}, {'aarskog-scott syndrome'}, {'intellectual developmental disorder, x-linked, syndromic, wu  iia'}, {'intellectual developmental disorder, x-linked, syndromic, wilson-turner  iia'}, {'intellectual developmental disorder with microcephaly and pontine and cerebellar hypoplasia'}, {'fragile 10 syndrome'}, {'intellectual developmental disorder, x-linked, syndromic, cabezas  iia'}, {'intellectual developmental disorder, x-linked, syndromic, claes-jensen  iia'}, {'martin-probst syndrome'}, {'intellectual developmental disorder, x-linked, syndromic, nascimento  iia'}, {'intellectual developmental disorder, x-linked, syndromic 33'}, {'intellectual developmental disorder, X-linked 109'}, {'intellectual developmental disorder, x-linked, syndromic 14'}, {'renpenning syndrome 1'}]\n",
      "\n",
      "    2. **Target Concept:**\n",
      "    **All its names:** {'Syndactyly type 5', 'Postaxial syndactyly with metacarpal synostosis', 'SD5'}\n",
      "    **Parent Concept Namings:** [{owl.Thing}, {'morphological anomaly'}, {'clinical entity'}]\n",
      "    **Child Concept Namings:** []\n",
      "\n",
      "    Write \"Yes\" if the concepts refer to the same entity, and \"No\" otherwise.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "src_entity = OntologyEntryAttr(test_case['SrcEntity'], onto_src)\n",
    "tgt_entity = OntologyEntryAttr(test_case['TgtEntity'], onto_tgt)\n",
    "\n",
    "candidate_idx = 0\n",
    "candidate_entity = OntologyEntryAttr(test_case['TgtCandidates'][candidate_idx], onto_tgt)\n",
    "\n",
    "prompt = dummy_prompt(src_entity, candidate_entity)\n",
    "# model_response = mistral.ask_question(prompt)\n",
    "# pred_answer = dummy_answer_extraction(model_response)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# set logging level to ignore most of the logs\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "src_entity = OntologyEntryAttr(test_case['SrcEntity'], onto_src)\n",
    "for idx, row in test_case_results_df.iterrows():\n",
    "    candidate_entity = OntologyEntryAttr(row['TgtCandidate'], onto_tgt)\n",
    "    prompt = dummy_prompt(src_entity, candidate_entity)\n",
    "    # model_response = mistral.ask_question(prompt)\n",
    "    model_response = 'Yes.' if random.random() > 0.8 else 'No.'\n",
    "    pred_answer = dummy_answer_extraction(model_response)\n",
    "    test_case_results_df.loc[idx, 'ModelResponse'] = model_response\n",
    "    test_case_results_df.loc[idx, 'ModelAnswer'] = pred_answer\n",
    "    # print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positively labeled targets: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcEntity</th>\n",
       "      <th>TgtCandidate</th>\n",
       "      <th>ModelAnswer</th>\n",
       "      <th>RealAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_93406</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_48471</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_85274</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_295195</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_1576</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_441434</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_93593</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_68385</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_98565</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_163971</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>http://www.omim.org/phenotypicSeries/PS309510</td>\n",
       "      <td>http://www.orpha.net/ORDO/Orphanet_225147</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        SrcEntity  \\\n",
       "0   http://www.omim.org/phenotypicSeries/PS309510   \n",
       "9   http://www.omim.org/phenotypicSeries/PS309510   \n",
       "24  http://www.omim.org/phenotypicSeries/PS309510   \n",
       "25  http://www.omim.org/phenotypicSeries/PS309510   \n",
       "70  http://www.omim.org/phenotypicSeries/PS309510   \n",
       "74  http://www.omim.org/phenotypicSeries/PS309510   \n",
       "75  http://www.omim.org/phenotypicSeries/PS309510   \n",
       "83  http://www.omim.org/phenotypicSeries/PS309510   \n",
       "86  http://www.omim.org/phenotypicSeries/PS309510   \n",
       "92  http://www.omim.org/phenotypicSeries/PS309510   \n",
       "97  http://www.omim.org/phenotypicSeries/PS309510   \n",
       "\n",
       "                                 TgtCandidate ModelAnswer RealAnswer  \n",
       "0    http://www.orpha.net/ORDO/Orphanet_93406         Yes         No  \n",
       "9    http://www.orpha.net/ORDO/Orphanet_48471         Yes         No  \n",
       "24   http://www.orpha.net/ORDO/Orphanet_85274         Yes         No  \n",
       "25  http://www.orpha.net/ORDO/Orphanet_295195         Yes         No  \n",
       "70    http://www.orpha.net/ORDO/Orphanet_1576         Yes         No  \n",
       "74  http://www.orpha.net/ORDO/Orphanet_441434         Yes         No  \n",
       "75   http://www.orpha.net/ORDO/Orphanet_93593         Yes         No  \n",
       "83   http://www.orpha.net/ORDO/Orphanet_68385         Yes         No  \n",
       "86   http://www.orpha.net/ORDO/Orphanet_98565         Yes         No  \n",
       "92  http://www.orpha.net/ORDO/Orphanet_163971         Yes         No  \n",
       "97  http://www.orpha.net/ORDO/Orphanet_225147         Yes         No  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_targets = test_case_results_df[test_case_results_df['ModelAnswer'] == 'Yes']\n",
    "print(f\"Number of positively labeled targets: {len(positive_targets)}\")\n",
    "positive_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extencive matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implication_prompt(source_entry, target_entry):\n",
    "    \"\"\"\n",
    "    Creates a prompt asking if 'source_entry' implies 'target_entry'.\n",
    "    Example: \"It is [a/an] C, is it a D? Yes/No\"\n",
    "    \"\"\"\n",
    "    return f\"It is [a/an] ${source_entry}$, is it a ${target_entry}$? Yes/No\"\n",
    "\n",
    "def equivalence_prompt(source_entry, target_entry):\n",
    "    \"\"\"\n",
    "    Creates prompts for both directions to check if 'source_entry' implies 'target_entry' and vice versa.\n",
    "    - Example: \"It is [a/an] C, is it a D? Yes/No\"\n",
    "    - Example: \"It is [a/an] D, is it a C? Yes/No\"\n",
    "    \"\"\"\n",
    "    prompt1 = implication_prompt(source_entry, target_entry)\n",
    "    prompt2 = implication_prompt(target_entry, source_entry)\n",
    "    return prompt1, prompt2\n",
    "\n",
    "def synonyms_prompt(source_label, target_label):\n",
    "    \"\"\"\n",
    "    Uses ontology to create prompts involving synonyms for C and D.\n",
    "    Example: \"It is [a/an] C-label2, is it a D-label3? Yes/No\"\n",
    "    \"\"\"\n",
    "    return f\"It is [a/an] ${source_label}$, is it a ${target_label}$? Yes/No\"\n",
    "\n",
    "def transitivity_prompt(source_entry, intermediate_entry, target_entry):\n",
    "    \"\"\"\n",
    "    Creates a transitivity prompt to check if 'source_entry' implies an intermediate entry,\n",
    "    which then implies 'target_entry'.\n",
    "    \"\"\"\n",
    "    return f\"It is [a/an] ${source_entry}$, implies ${intermediate_entry}$, implies ${target_entry}$? Yes/No\"\n",
    "\n",
    "def hierarchical_equivalence_prompt(child1, parent1, child2, parent2):\n",
    "    \"\"\"\n",
    "    Creates prompts to check bidirectional equivalence between two hierarchical entries.\n",
    "    Example:\n",
    "    - \"Something is [a/an] C and [a/an] C', is it also [a/an] D and [a/an] D'? Yes/No\"\n",
    "    - \"Something is [a/an] D and [a/an] D', is it also [a/an] C and [a/an] C'? Yes/No\"\n",
    "    \"\"\"\n",
    "    prompt1 = f\"Something is [a/an] ${child1}$ and [a/an] ${parent1}$, is it also [a/an] ${child2}$ and [a/an] ${parent2}$? Yes/No\"\n",
    "    prompt2 = f\"Something is [a/an] ${child2}$ and [a/an] ${parent2}$, is it also [a/an] ${child1}$ and [a/an] ${parent1}$? Yes/No\"\n",
    "    return prompt1, prompt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:59:16.659816Z",
     "iopub.status.busy": "2024-11-12T11:59:16.659061Z",
     "iopub.status.idle": "2024-11-12T11:59:16.671564Z",
     "shell.execute_reply": "2024-11-12T11:59:16.670577Z",
     "shell.execute_reply.started": "2024-11-12T11:59:16.659774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def local_matching_confidence(source_entry, target_entry, onto_1=None, onto_2=None):\n",
    "    # TODO: change this function to use the General Model\n",
    "    # TODO: implement response parsing\n",
    "    source_attr = OntologyEntryAttr(source_entry, onto_1)\n",
    "    target_attr = OntologyEntryAttr(target_entry, onto_2)\n",
    "\n",
    "    general_points = 0\n",
    "    retrieved_points = 0\n",
    "\n",
    "    # Note: All names already includes Synonyms and Main Labels as well\n",
    "    # compare names\n",
    "    for s in source_attr.getAllEntetyNames():\n",
    "        for t in target_attr.getAllEntetyNames():\n",
    "            e1, e2 = equivalence_prompt(s, t)\n",
    "            q1 = mistral.ask_question(e1)\n",
    "            q2 = mistral.ask_question(e2)\n",
    "            if  \"Yes\" in q1:\n",
    "                retrieved_points += 1\n",
    "            if \"Yes\" in q2:\n",
    "                retrieved_points += 1\n",
    "            if \"Yes\" in q1 and \"Yes\" in q2:\n",
    "                retrieved_points += 1\n",
    "            print(retrieved_points/(general_points + 1e-6))\n",
    "            general_points += 3\n",
    "\n",
    "    # compare synonyms\n",
    "    for s in source_attr.getSynonyms():\n",
    "        for t in target_attr.getSynonyms():\n",
    "            e = synonyms_prompt(s, t)\n",
    "            q = mistral.ask_question(e)\n",
    "            if \"Yes\" in q:\n",
    "                retrieved_points += 1\n",
    "            general_points += 1\n",
    "            print(retrieved_points/(general_points + 1e-6))\n",
    "\n",
    "    # compare hierarchy\n",
    "    source_hierarchy = {\n",
    "        \"children\": source_attr.getChildren(),\n",
    "        \"parents\": source_attr.getParents()\n",
    "    }\n",
    "\n",
    "    target_hierarchy = {\n",
    "        \"children\": target_attr.getChildren(),\n",
    "        \"parents\": target_attr.getParents()\n",
    "    }\n",
    "\n",
    "    for schild in source_hierarchy[\"children\"]:\n",
    "        for tchild in target_hierarchy[\"children\"]:\n",
    "            if source_hierarchy[\"parents\"] and target_hierarchy[\"parents\"]:\n",
    "                for sparent, tparent in zip(source_hierarchy[\"parents\"], target_hierarchy[\"parents\"]):\n",
    "                    e1, e2 = hierarchical_equivalence_prompt(schild, sparent, tchild, tparent)\n",
    "                    \n",
    "                    q1 = mistral.ask_question(e1)\n",
    "                    q2 = mistral.ask_question(e2)\n",
    "                    \n",
    "                    retrieved_points += (\"Yes\" in q1) + (\"Yes\" in q2)\n",
    "                    if \"Yes\" in q1 and \"Yes\" in q2:\n",
    "                        retrieved_points += 1\n",
    "                    \n",
    "                    general_points += 3\n",
    "                    print(retrieved_points / (general_points + 1e-6))\n",
    "\n",
    "\n",
    "    confidence = retrieved_points / general_points\n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:59:16.673561Z",
     "iopub.status.busy": "2024-11-12T11:59:16.673199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to calculate confidences\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# confidences = {}\n",
    "\n",
    "# for _, row in tqdm(test_candidates.iterrows(), total=test_candidates.shape[0], desc=\"Processing rows\"):\n",
    "#     source = row[0]\n",
    "#     target = row[1]\n",
    "#     confidences[(source, target)] = []\n",
    "\n",
    "#     for candidate in tqdm(row[2], desc=f\"Processing candidates for ({source}, {target})\", leave=False):\n",
    "#         confidence = local_matching_confidence(source, candidate, onto_1=onto_src, onto_2=onto_tgt)\n",
    "#         confidences[(source, target)].append((candidate, confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Filtering with Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"dunzhang/stella_en_1.5B_v5\", trust_remote_code=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threshold = 0.9\n",
    "similarities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_entity_name = list(OntologyEntryAttr(test_case['SrcEntity'], onto_src).getAllEntetyNames())[0]\n",
    "tgt_entity_name = list(OntologyEntryAttr(test_case['TgtEntity'], onto_tgt).getAllEntetyNames())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in test_case_results_df.iterrows():\n",
    "    tgt_candidate = row['TgtCandidate']\n",
    "    candidate_entity_name = list(OntologyEntryAttr(tgt_candidate, onto_tgt).getAllEntetyNames())[0]\n",
    "    similarity = model.similarity(model.encode(src_entity_name), model.encode(candidate_entity_name))\n",
    "    similarities[tgt_candidate] = similarity\n",
    "    print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('output.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Key', 'Value'])  # Header row\n",
    "    for key, value in similarities.items():\n",
    "        writer.writerow([key, value.item()])\n",
    "\n",
    "print(\"Data saved to output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ranked_candidates = {}\n",
    "\n",
    "for source, target, candidates in tqdm(test_candidates.iterrows(), total=test_candidates.shape[0], desc=\"Processing rows\"):\n",
    "    ranked_candidates[(source, target)] = sorted(\n",
    "        [(candidate, local_matching_confidence(source, candidate)) \n",
    "         for candidate in tqdm(candidates, desc=f\"Processing candidates for {source}\", leave=False)],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_at_K(test_data, ranked_candidates, K):\n",
    "    hits = 0\n",
    "    for source, target, _, in test_candidates.iterrows():\n",
    "        top_k_candidates = [candidate for candidate, _ in ranked_candidates[(source, target)][:K]]\n",
    "        if target in top_k_candidates:\n",
    "            hits += 1\n",
    "    return hits / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "hits = hits_at_K(test_candidates, ranked_candidates, K)\n",
    "print(f\"Hits@{K}: {hits:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6011590,
     "sourceId": 9807256,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 1902,
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
